PS C:\DDrive\MyData\Yogesh\git_repo\DevOps\kubernetes\aws-eks> terraform plan
Refreshing Terraform state in-memory prior to plan...
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.

data.aws_iam_policy_document.workers_assume_role_policy: Refreshing state...
data.aws_caller_identity.current: Refreshing state...
data.aws_region.current: Refreshing state...
data.aws_iam_policy_document.cluster_assume_role_policy: Refreshing state...
data.aws_ami.eks_worker: Refreshing state...

------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

 <= module.eks.data.aws_iam_policy_document.worker_autoscaling
      id:                                                 <computed>
      json:                                               <computed>
      statement.#:                                        "2"
      statement.0.actions.#:                              "5"
      statement.0.actions.1274732150:                     "autoscaling:DescribeAutoScalingGroups"
      statement.0.actions.2448883636:                     "autoscaling:DescribeAutoScalingInstances"
      statement.0.actions.2555065653:                     "autoscaling:DescribeLaunchConfigurations"
      statement.0.actions.3701464416:                     "autoscaling:DescribeTags"
      statement.0.actions.4281419483:                     "autoscaling:GetAsgForInstance"
      statement.0.effect:                                 "Allow"
      statement.0.resources.#:                            "1"
      statement.0.resources.2679715827:                   "*"
      statement.0.sid:                                    "eksWorkerAutoscalingAll"
      statement.1.actions.#:                              "3"
      statement.1.actions.1536675971:                     "autoscaling:UpdateAutoScalingGroup"
      statement.1.actions.3469696720:                     "autoscaling:TerminateInstanceInAutoScalingGroup"
      statement.1.actions.557626329:                      "autoscaling:SetDesiredCapacity"
      statement.1.condition.#:                            "2"
      statement.1.condition.3636405986.test:              "StringEquals"
      statement.1.condition.3636405986.values.#:          "1"
      statement.1.condition.3636405986.values.4043113848: "true"
      statement.1.condition.3636405986.variable:          "autoscaling:ResourceTag/k8s.io/cluster-autoscaler/enabled"
      statement.1.condition.4028998177.test:              "StringEquals"
      statement.1.condition.4028998177.values.#:          "1"
      statement.1.condition.4028998177.values.653127311:  "owned"
      statement.1.condition.4028998177.variable:          "autoscaling:ResourceTag/kubernetes.io/cluster/poi-eks-cluster"
      statement.1.effect:                                 "Allow"
      statement.1.resources.#:                            "1"
      statement.1.resources.2679715827:                   "*"
      statement.1.sid:                                    "eksWorkerAutoscalingOwn"

 <= module.eks.data.template_file.config_map_aws_auth
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: aws-auth\n  namespace: kube-system\ndata:\n  mapRoles: |\n${wor
ker_role_arn}\n${map_roles}\n  mapUsers: |\n${map_users}\n  mapAccounts: |\n${map_accounts}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.kubeconfig
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "apiVersion: v1\npreferences: {}\nkind: Config\n\nclusters:\n- cluster:\n    server: ${endpoint}\n    certificate-au
thority-data: ${cluster_auth_base64}\n  name: ${kubeconfig_name}\n\ncontexts:\n- context:\n    cluster: ${kubeconfig_name}\n    user: ${kubeconfig_name}\n  name: ${kubeconfig
_name}\n\ncurrent-context: ${kubeconfig_name}\n\nusers:\n- name: ${kubeconfig_name}\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1alpha1\n      comman
d: ${aws_authenticator_command}\n      args:\n        - \"token\"\n        - \"-i\"\n        - \"${cluster_name}\"\n${aws_authenticator_additional_args}\n${aws_authenticator_
env_variables}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.userdata
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "#!/bin/bash -xe\n\n# Allow user supplied pre userdata code\n${pre_userdata}\n\n# Bootstrap and join the cluster\n/e
tc/eks/bootstrap.sh --b64-cluster-ca '${cluster_auth_base64}' --apiserver-endpoint '${endpoint}' --kubelet-extra-args '${kubelet_extra_args}' '${cluster_name}'\n\n# Allow use
r supplied userdata code\n${additional_userdata}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.worker_role_arns
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "    - rolearn: ${worker_role_arn}\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - syst
em:bootstrappers\n        - system:nodes\n"
      vars.%:                                             <computed>

  + module.eks.aws_autoscaling_group.workers
      id:                                                 <computed>
      arn:                                                <computed>
      availability_zones.#:                               <computed>
      default_cooldown:                                   <computed>
      desired_capacity:                                   "0"
      force_delete:                                       "false"
      health_check_grace_period:                          "300"
      health_check_type:                                  <computed>
      launch_configuration:                               "${element(aws_launch_configuration.workers.*.id, count.index)}"
      load_balancers.#:                                   <computed>
      max_size:                                           "0"
      metrics_granularity:                                "1Minute"
      min_size:                                           "0"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-0"
      protect_from_scale_in:                              "false"
      service_linked_role_arn:                            <computed>
      tags.#:                                             <computed>
      target_group_arns.#:                                <computed>
      vpc_zone_identifier.#:                              <computed>
      wait_for_capacity_timeout:                          "10m"

  + module.eks.aws_eks_cluster.this
      id:                                                 <computed>
      arn:                                                <computed>
      certificate_authority.#:                            <computed>
      created_at:                                         <computed>
      endpoint:                                           <computed>
      name:                                               "poi-eks-cluster"
      platform_version:                                   <computed>
      role_arn:                                           "${aws_iam_role.cluster.arn}"
      version:                                            "1.10"
      vpc_config.#:                                       "1"
      vpc_config.0.security_group_ids.#:                  <computed>
      vpc_config.0.subnet_ids.#:                          "4"
      vpc_config.0.subnet_ids.360204655:                  "subnet-8813e1ec"
      vpc_config.0.subnet_ids.4209864939:                 "subnet-a3685afa"
      vpc_config.0.subnet_ids.4225826129:                 "subnet-a850bce0"
      vpc_config.0.subnet_ids.459373779:                  "subnet-c11f05b6"
      vpc_config.0.vpc_id:                                <computed>

  + module.eks.aws_iam_instance_profile.workers
      id:                                                 <computed>
      arn:                                                <computed>
      create_date:                                        <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      role:                                               "${lookup(var.worker_groups[count.index], \"iam_role_id\",  lookup(local.workers_group_defaults, \"iam_role_id\"))}"
      roles.#:                                            <computed>
      unique_id:                                          <computed>

  + module.eks.aws_iam_policy.worker_autoscaling
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "EKS worker node autoscaling policy for cluster poi-eks-cluster"
      name:                                               <computed>
      name_prefix:                                        "eks-worker-autoscaling-poi-eks-cluster"
      path:                                               "/"
      policy:                                             "${data.aws_iam_policy_document.worker_autoscaling.json}"

  + module.eks.aws_iam_role.cluster
      id:                                                 <computed>
      arn:                                                <computed>
      assume_role_policy:                                 "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSClusterAssumeRole\",\n      \"Eff
ect\": \"Allow\",\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"eks.amazonaws.com\"\n      }\n    }\n  ]\n}"
      create_date:                                        <computed>
      force_detach_policies:                              "false"
      max_session_duration:                               "3600"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      unique_id:                                          <computed>

  + module.eks.aws_iam_role.workers
      id:                                                 <computed>
      arn:                                                <computed>
      assume_role_policy:                                 "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSWorkerAssumeRole\",\n      \"Effe
ct\": \"Allow\",\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      }\n    }\n  ]\n}"
      create_date:                                        <computed>
      force_detach_policies:                              "false"
      max_session_duration:                               "3600"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      unique_id:                                          <computed>

  + module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
      role:                                               "${aws_iam_role.cluster.name}"

  + module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSServicePolicy"
      role:                                               "${aws_iam_role.cluster.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_autoscaling
      id:                                                 <computed>
      policy_arn:                                         "${aws_iam_policy.worker_autoscaling.arn}"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_launch_configuration.workers
      id:                                                 <computed>
      associate_public_ip_address:                        "false"
      ebs_block_device.#:                                 <computed>
      ebs_optimized:                                      "false"
      enable_monitoring:                                  "false"
      iam_instance_profile:                               "${element(aws_iam_instance_profile.workers.*.id, count.index)}"
      image_id:                                           "${lookup(var.worker_groups[count.index], \"ami_id\", local.workers_group_defaults[\"ami_id\"])}"
      instance_type:                                      "${lookup(var.worker_groups[count.index], \"instance_type\", local.workers_group_defaults[\"instance_type\"])}"
      key_name:                                           "${lookup(var.worker_groups[count.index], \"key_name\", local.workers_group_defaults[\"key_name\"])}"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-0"
      placement_tenancy:                                  "${lookup(var.worker_groups[count.index], \"placement_tenancy\", local.workers_group_defaults[\"placement_tenancy\"]
)}"
      root_block_device.#:                                "1"
      root_block_device.0.delete_on_termination:          "true"
      root_block_device.0.iops:                           "0"
      root_block_device.0.volume_size:                    "0"
      root_block_device.0.volume_type:                    "${lookup(var.worker_groups[count.index], \"root_volume_type\", local.workers_group_defaults[\"root_volume_type\"])}
"
      security_groups.#:                                  <computed>
      spot_price:                                         "${lookup(var.worker_groups[count.index], \"spot_price\", local.workers_group_defaults[\"spot_price\"])}"
      user_data_base64:                                   "${base64encode(element(data.template_file.userdata.*.rendered, count.index))}"

  + module.eks.aws_security_group.cluster
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "EKS cluster security group."
      egress.#:                                           <computed>
      ingress.#:                                          <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      owner_id:                                           <computed>
      revoke_rules_on_delete:                             "false"
      tags.%:                                             "2"
      tags.Environment:                                   "poi-eks-env"
      tags.Name:                                          "poi-eks-cluster-eks_cluster_sg"
      vpc_id:                                             "vpc-3842495d"

  + module.eks.aws_security_group.workers
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "Security group for all nodes in the cluster."
      egress.#:                                           <computed>
      ingress.#:                                          <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      owner_id:                                           <computed>
      revoke_rules_on_delete:                             "false"
      tags.%:                                             "3"
      tags.Environment:                                   "poi-eks-env"
      tags.Name:                                          "poi-eks-cluster-eks_worker_sg"
      tags.kubernetes.io/cluster/poi-eks-cluster:         "owned"
      vpc_id:                                             "vpc-3842495d"

  + module.eks.aws_security_group_rule.cluster_egress_internet
      id:                                                 <computed>
      cidr_blocks.#:                                      "1"
      cidr_blocks.0:                                      "0.0.0.0/0"
      description:                                        "Allow cluster egress access to the Internet."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.cluster.id}"
      self:                                               "false"
      source_security_group_id:                           <computed>
      to_port:                                            "0"
      type:                                               "egress"

  + module.eks.aws_security_group_rule.cluster_https_worker_ingress
      id:                                                 <computed>
      description:                                        "Allow pods to communicate with the EKS cluster API."
      from_port:                                          "443"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.cluster.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.worker_security_group_id}"
      to_port:                                            "443"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_egress_internet
      id:                                                 <computed>
      cidr_blocks.#:                                      "1"
      cidr_blocks.0:                                      "0.0.0.0/0"
      description:                                        "Allow nodes all egress to the Internet."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           <computed>
      to_port:                                            "0"
      type:                                               "egress"

  + module.eks.aws_security_group_rule.workers_ingress_cluster
      id:                                                 <computed>
      description:                                        "Allow workers Kubelets and pods to receive communication from the cluster control plane."
      from_port:                                          "1025"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.cluster_security_group_id}"
      to_port:                                            "65535"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_ingress_cluster_https
      id:                                                 <computed>
      description:                                        "Allow pods running extension API servers on port 443 to receive communication from cluster control plane."
      from_port:                                          "443"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.cluster_security_group_id}"
      to_port:                                            "443"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_ingress_self
      id:                                                 <computed>
      description:                                        "Allow node to communicate with each other."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${aws_security_group.workers.id}"
      to_port:                                            "65535"
      type:                                               "ingress"

  + module.eks.local_file.config_map_aws_auth
      id:                                                 <computed>
      content:                                            "${data.template_file.config_map_aws_auth.rendered}"
      filename:                                           "./config-map-aws-auth_poi-eks-cluster.yaml"

  + module.eks.local_file.kubeconfig
      id:                                                 <computed>
      content:                                            "${data.template_file.kubeconfig.rendered}"
      filename:                                           "./kubeconfig_poi-eks-cluster"

  + module.eks.null_resource.tags_as_list_of_maps
      id:                                                 <computed>
      triggers.%:                                         "3"
      triggers.key:                                       "Environment"
      triggers.propagate_at_launch:                       "true"
      triggers.value:                                     "poi-eks-env"

  + module.eks.null_resource.update_config_map_aws_auth
      id:                                                 <computed>
      triggers.%:                                         <computed>


Plan: 25 to add, 0 to change, 0 to destroy.

------------------------------------------------------------------------

Note: You didn't specify an "-out" parameter to save this plan, so Terraform
can't guarantee that exactly these actions will be performed if
"terraform apply" is subsequently run.

PS C:\DDrive\MyData\Yogesh\git_repo\DevOps\kubernetes\aws-eks> terraform apply
data.aws_caller_identity.current: Refreshing state...
data.aws_region.current: Refreshing state...
data.aws_ami.eks_worker: Refreshing state...
data.aws_iam_policy_document.workers_assume_role_policy: Refreshing state...
data.aws_iam_policy_document.cluster_assume_role_policy: Refreshing state...

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

 <= module.eks.data.aws_iam_policy_document.worker_autoscaling
      id:                                                 <computed>
      json:                                               <computed>
      statement.#:                                        "2"
      statement.0.actions.#:                              "5"
      statement.0.actions.1274732150:                     "autoscaling:DescribeAutoScalingGroups"
      statement.0.actions.2448883636:                     "autoscaling:DescribeAutoScalingInstances"
      statement.0.actions.2555065653:                     "autoscaling:DescribeLaunchConfigurations"
      statement.0.actions.3701464416:                     "autoscaling:DescribeTags"
      statement.0.actions.4281419483:                     "autoscaling:GetAsgForInstance"
      statement.0.effect:                                 "Allow"
      statement.0.resources.#:                            "1"
      statement.0.resources.2679715827:                   "*"
      statement.0.sid:                                    "eksWorkerAutoscalingAll"
      statement.1.actions.#:                              "3"
      statement.1.actions.1536675971:                     "autoscaling:UpdateAutoScalingGroup"
      statement.1.actions.3469696720:                     "autoscaling:TerminateInstanceInAutoScalingGroup"
      statement.1.actions.557626329:                      "autoscaling:SetDesiredCapacity"
      statement.1.condition.#:                            "2"
      statement.1.condition.3636405986.test:              "StringEquals"
      statement.1.condition.3636405986.values.#:          "1"
      statement.1.condition.3636405986.values.4043113848: "true"
      statement.1.condition.3636405986.variable:          "autoscaling:ResourceTag/k8s.io/cluster-autoscaler/enabled"
      statement.1.condition.4028998177.test:              "StringEquals"
      statement.1.condition.4028998177.values.#:          "1"
      statement.1.condition.4028998177.values.653127311:  "owned"
      statement.1.condition.4028998177.variable:          "autoscaling:ResourceTag/kubernetes.io/cluster/poi-eks-cluster"
      statement.1.effect:                                 "Allow"
      statement.1.resources.#:                            "1"
      statement.1.resources.2679715827:                   "*"
      statement.1.sid:                                    "eksWorkerAutoscalingOwn"

 <= module.eks.data.template_file.config_map_aws_auth
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: aws-auth\n  namespace: kube-system\ndata:\n  mapRoles: |\n${wor
ker_role_arn}\n${map_roles}\n  mapUsers: |\n${map_users}\n  mapAccounts: |\n${map_accounts}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.kubeconfig
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "apiVersion: v1\npreferences: {}\nkind: Config\n\nclusters:\n- cluster:\n    server: ${endpoint}\n    certificate-au
thority-data: ${cluster_auth_base64}\n  name: ${kubeconfig_name}\n\ncontexts:\n- context:\n    cluster: ${kubeconfig_name}\n    user: ${kubeconfig_name}\n  name: ${kubeconfig
_name}\n\ncurrent-context: ${kubeconfig_name}\n\nusers:\n- name: ${kubeconfig_name}\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1alpha1\n      comman
d: ${aws_authenticator_command}\n      args:\n        - \"token\"\n        - \"-i\"\n        - \"${cluster_name}\"\n${aws_authenticator_additional_args}\n${aws_authenticator_
env_variables}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.userdata
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "#!/bin/bash -xe\n\n# Allow user supplied pre userdata code\n${pre_userdata}\n\n# Bootstrap and join the cluster\n/e
tc/eks/bootstrap.sh --b64-cluster-ca '${cluster_auth_base64}' --apiserver-endpoint '${endpoint}' --kubelet-extra-args '${kubelet_extra_args}' '${cluster_name}'\n\n# Allow use
r supplied userdata code\n${additional_userdata}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.worker_role_arns
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "    - rolearn: ${worker_role_arn}\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - syst
em:bootstrappers\n        - system:nodes\n"
      vars.%:                                             <computed>

  + module.eks.aws_autoscaling_group.workers
      id:                                                 <computed>
      arn:                                                <computed>
      availability_zones.#:                               <computed>
      default_cooldown:                                   <computed>
      desired_capacity:                                   "0"
      force_delete:                                       "false"
      health_check_grace_period:                          "300"
      health_check_type:                                  <computed>
      launch_configuration:                               "${element(aws_launch_configuration.workers.*.id, count.index)}"
      load_balancers.#:                                   <computed>
      max_size:                                           "0"
      metrics_granularity:                                "1Minute"
      min_size:                                           "0"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-0"
      protect_from_scale_in:                              "false"
      service_linked_role_arn:                            <computed>
      tags.#:                                             <computed>
      target_group_arns.#:                                <computed>
      vpc_zone_identifier.#:                              <computed>
      wait_for_capacity_timeout:                          "10m"

  + module.eks.aws_eks_cluster.this
      id:                                                 <computed>
      arn:                                                <computed>
      certificate_authority.#:                            <computed>
      created_at:                                         <computed>
      endpoint:                                           <computed>
      name:                                               "poi-eks-cluster"
      platform_version:                                   <computed>
      role_arn:                                           "${aws_iam_role.cluster.arn}"
      version:                                            "1.10"
      vpc_config.#:                                       "1"
      vpc_config.0.security_group_ids.#:                  <computed>
      vpc_config.0.subnet_ids.#:                          "4"
      vpc_config.0.subnet_ids.360204655:                  "subnet-8813e1ec"
      vpc_config.0.subnet_ids.4209864939:                 "subnet-a3685afa"
      vpc_config.0.subnet_ids.4225826129:                 "subnet-a850bce0"
      vpc_config.0.subnet_ids.459373779:                  "subnet-c11f05b6"
      vpc_config.0.vpc_id:                                <computed>

  + module.eks.aws_iam_instance_profile.workers
      id:                                                 <computed>
      arn:                                                <computed>
      create_date:                                        <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      role:                                               "${lookup(var.worker_groups[count.index], \"iam_role_id\",  lookup(local.workers_group_defaults, \"iam_role_id\"))}"
      roles.#:                                            <computed>
      unique_id:                                          <computed>

  + module.eks.aws_iam_policy.worker_autoscaling
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "EKS worker node autoscaling policy for cluster poi-eks-cluster"
      name:                                               <computed>
      name_prefix:                                        "eks-worker-autoscaling-poi-eks-cluster"
      path:                                               "/"
      policy:                                             "${data.aws_iam_policy_document.worker_autoscaling.json}"

  + module.eks.aws_iam_role.cluster
      id:                                                 <computed>
      arn:                                                <computed>
      assume_role_policy:                                 "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSClusterAssumeRole\",\n      \"Eff
ect\": \"Allow\",\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"eks.amazonaws.com\"\n      }\n    }\n  ]\n}"
      create_date:                                        <computed>
      force_detach_policies:                              "false"
      max_session_duration:                               "3600"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      unique_id:                                          <computed>

  + module.eks.aws_iam_role.workers
      id:                                                 <computed>
      arn:                                                <computed>
      assume_role_policy:                                 "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSWorkerAssumeRole\",\n      \"Effe
ct\": \"Allow\",\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      }\n    }\n  ]\n}"
      create_date:                                        <computed>
      force_detach_policies:                              "false"
      max_session_duration:                               "3600"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      unique_id:                                          <computed>

  + module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
      role:                                               "${aws_iam_role.cluster.name}"

  + module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSServicePolicy"
      role:                                               "${aws_iam_role.cluster.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_autoscaling
      id:                                                 <computed>
      policy_arn:                                         "${aws_iam_policy.worker_autoscaling.arn}"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_launch_configuration.workers
      id:                                                 <computed>
      associate_public_ip_address:                        "false"
      ebs_block_device.#:                                 <computed>
      ebs_optimized:                                      "false"
      enable_monitoring:                                  "false"
      iam_instance_profile:                               "${element(aws_iam_instance_profile.workers.*.id, count.index)}"
      image_id:                                           "${lookup(var.worker_groups[count.index], \"ami_id\", local.workers_group_defaults[\"ami_id\"])}"
      instance_type:                                      "${lookup(var.worker_groups[count.index], \"instance_type\", local.workers_group_defaults[\"instance_type\"])}"
      key_name:                                           "${lookup(var.worker_groups[count.index], \"key_name\", local.workers_group_defaults[\"key_name\"])}"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-0"
      placement_tenancy:                                  "${lookup(var.worker_groups[count.index], \"placement_tenancy\", local.workers_group_defaults[\"placement_tenancy\"]
)}"
      root_block_device.#:                                "1"
      root_block_device.0.delete_on_termination:          "true"
      root_block_device.0.iops:                           "0"
      root_block_device.0.volume_size:                    "0"
      root_block_device.0.volume_type:                    "${lookup(var.worker_groups[count.index], \"root_volume_type\", local.workers_group_defaults[\"root_volume_type\"])}
"
      security_groups.#:                                  <computed>
      spot_price:                                         "${lookup(var.worker_groups[count.index], \"spot_price\", local.workers_group_defaults[\"spot_price\"])}"
      user_data_base64:                                   "${base64encode(element(data.template_file.userdata.*.rendered, count.index))}"

  + module.eks.aws_security_group.cluster
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "EKS cluster security group."
      egress.#:                                           <computed>
      ingress.#:                                          <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      owner_id:                                           <computed>
      revoke_rules_on_delete:                             "false"
      tags.%:                                             "2"
      tags.Environment:                                   "poi-eks-env"
      tags.Name:                                          "poi-eks-cluster-eks_cluster_sg"
      vpc_id:                                             "vpc-3842495d"

  + module.eks.aws_security_group.workers
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "Security group for all nodes in the cluster."
      egress.#:                                           <computed>
      ingress.#:                                          <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      owner_id:                                           <computed>
      revoke_rules_on_delete:                             "false"
      tags.%:                                             "3"
      tags.Environment:                                   "poi-eks-env"
      tags.Name:                                          "poi-eks-cluster-eks_worker_sg"
      tags.kubernetes.io/cluster/poi-eks-cluster:         "owned"
      vpc_id:                                             "vpc-3842495d"

  + module.eks.aws_security_group_rule.cluster_egress_internet
      id:                                                 <computed>
      cidr_blocks.#:                                      "1"
      cidr_blocks.0:                                      "0.0.0.0/0"
      description:                                        "Allow cluster egress access to the Internet."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.cluster.id}"
      self:                                               "false"
      source_security_group_id:                           <computed>
      to_port:                                            "0"
      type:                                               "egress"

  + module.eks.aws_security_group_rule.cluster_https_worker_ingress
      id:                                                 <computed>
      description:                                        "Allow pods to communicate with the EKS cluster API."
      from_port:                                          "443"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.cluster.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.worker_security_group_id}"
      to_port:                                            "443"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_egress_internet
      id:                                                 <computed>
      cidr_blocks.#:                                      "1"
      cidr_blocks.0:                                      "0.0.0.0/0"
      description:                                        "Allow nodes all egress to the Internet."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           <computed>
      to_port:                                            "0"
      type:                                               "egress"

  + module.eks.aws_security_group_rule.workers_ingress_cluster
      id:                                                 <computed>
      description:                                        "Allow workers Kubelets and pods to receive communication from the cluster control plane."
      from_port:                                          "1025"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.cluster_security_group_id}"
      to_port:                                            "65535"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_ingress_cluster_https
      id:                                                 <computed>
      description:                                        "Allow pods running extension API servers on port 443 to receive communication from cluster control plane."
      from_port:                                          "443"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.cluster_security_group_id}"
      to_port:                                            "443"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_ingress_self
      id:                                                 <computed>
      description:                                        "Allow node to communicate with each other."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${aws_security_group.workers.id}"
      to_port:                                            "65535"
      type:                                               "ingress"

  + module.eks.local_file.config_map_aws_auth
      id:                                                 <computed>
      content:                                            "${data.template_file.config_map_aws_auth.rendered}"
      filename:                                           "./config-map-aws-auth_poi-eks-cluster.yaml"

  + module.eks.local_file.kubeconfig
      id:                                                 <computed>
      content:                                            "${data.template_file.kubeconfig.rendered}"
      filename:                                           "./kubeconfig_poi-eks-cluster"

  + module.eks.null_resource.tags_as_list_of_maps
      id:                                                 <computed>
      triggers.%:                                         "3"
      triggers.key:                                       "Environment"
      triggers.propagate_at_launch:                       "true"
      triggers.value:                                     "poi-eks-env"

  + module.eks.null_resource.update_config_map_aws_auth
      id:                                                 <computed>
      triggers.%:                                         <computed>


Plan: 25 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

module.eks.null_resource.tags_as_list_of_maps: Creating...
  triggers.%:                   "" => "3"
  triggers.key:                 "" => "Environment"
  triggers.propagate_at_launch: "" => "true"
  triggers.value:               "" => "poi-eks-env"
module.eks.null_resource.tags_as_list_of_maps: Creation complete after 0s (ID: 9002294971603423036)
module.eks.aws_iam_role.cluster: Creating...
  arn:                   "" => "<computed>"
  assume_role_policy:    "" => "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSClusterAssumeRole\",\n      \"Effect\": \"Allow\",\n      \"
Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"eks.amazonaws.com\"\n      }\n    }\n  ]\n}"
  create_date:           "" => "<computed>"
  force_detach_policies: "" => "false"
  max_session_duration:  "" => "3600"
  name:                  "" => "<computed>"
  name_prefix:           "" => "poi-eks-cluster"
  path:                  "" => "/"
  unique_id:             "" => "<computed>"
module.eks.aws_security_group.cluster: Creating...
  arn:                    "" => "<computed>"
  description:            "" => "EKS cluster security group."
  egress.#:               "" => "<computed>"
  ingress.#:              "" => "<computed>"
  name:                   "" => "<computed>"
  name_prefix:            "" => "poi-eks-cluster"
  owner_id:               "" => "<computed>"
  revoke_rules_on_delete: "" => "false"
  tags.%:                 "" => "2"
  tags.Environment:       "" => "poi-eks-env"
  tags.Name:              "" => "poi-eks-cluster-eks_cluster_sg"
  vpc_id:                 "" => "vpc-3842495d"
module.eks.aws_iam_role.cluster: Creation complete after 4s (ID: poi-eks-cluster20181112145042729000000001)
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy: Creating...
  policy_arn: "" => "arn:aws:iam::aws:policy/AmazonEKSServicePolicy"
  role:       "" => "poi-eks-cluster20181112145042729000000001"
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy: Creating...
  policy_arn: "" => "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
  role:       "" => "poi-eks-cluster20181112145042729000000001"
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy: Creation complete after 5s (ID: poi-eks-cluster20181112145042729000000001-20181112145048761900000003
)
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy: Creation complete after 5s (ID: poi-eks-cluster20181112145042729000000001-20181112145048774900000004
)
module.eks.aws_security_group.cluster: Still creating... (10s elapsed)
module.eks.aws_security_group.cluster: Creation complete after 11s (ID: sg-03e51eeeb304dd9b6)
module.eks.aws_security_group_rule.cluster_egress_internet: Creating...
  cidr_blocks.#:            "" => "1"
  cidr_blocks.0:            "" => "0.0.0.0/0"
  description:              "" => "Allow cluster egress access to the Internet."
  from_port:                "" => "0"
  protocol:                 "" => "-1"
  security_group_id:        "" => "sg-03e51eeeb304dd9b6"
  self:                     "" => "false"
  source_security_group_id: "" => "<computed>"
  to_port:                  "" => "0"
  type:                     "" => "egress"
module.eks.aws_eks_cluster.this: Creating...
  arn:                                        "" => "<computed>"
  certificate_authority.#:                    "" => "<computed>"
  created_at:                                 "" => "<computed>"
  endpoint:                                   "" => "<computed>"
  name:                                       "" => "poi-eks-cluster"
  platform_version:                           "" => "<computed>"
  role_arn:                                   "" => "arn:aws:iam::077978206904:role/poi-eks-cluster20181112145042729000000001"
  version:                                    "" => "1.10"
  vpc_config.#:                               "" => "1"
  vpc_config.0.security_group_ids.#:          "" => "1"
  vpc_config.0.security_group_ids.3322252694: "" => "sg-03e51eeeb304dd9b6"
  vpc_config.0.subnet_ids.#:                  "" => "4"
  vpc_config.0.subnet_ids.360204655:          "" => "subnet-8813e1ec"
  vpc_config.0.subnet_ids.4209864939:         "" => "subnet-a3685afa"
  vpc_config.0.subnet_ids.4225826129:         "" => "subnet-a850bce0"
  vpc_config.0.subnet_ids.459373779:          "" => "subnet-c11f05b6"
  vpc_config.0.vpc_id:                        "" => "<computed>"
module.eks.aws_security_group_rule.cluster_egress_internet: Creation complete after 5s (ID: sgrule-3008376012)
module.eks.aws_eks_cluster.this: Still creating... (10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (9m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (9m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (9m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (9m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (9m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (9m50s elapsed)
module.eks.aws_eks_cluster.this: Creation complete after 9m53s (ID: poi-eks-cluster)
module.eks.aws_iam_role.workers: Creating...
  arn:                   "" => "<computed>"
  assume_role_policy:    "" => "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSWorkerAssumeRole\",\n      \"Effect\": \"Allow\",\n      \"A
ction\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      }\n    }\n  ]\n}"
  create_date:           "" => "<computed>"
  force_detach_policies: "" => "false"
  max_session_duration:  "" => "3600"
  name:                  "" => "<computed>"
  name_prefix:           "" => "poi-eks-cluster"
  path:                  "" => "/"
  unique_id:             "" => "<computed>"
module.eks.aws_security_group.workers: Creating...
  arn:                                        "" => "<computed>"
  description:                                "" => "Security group for all nodes in the cluster."
  egress.#:                                   "" => "<computed>"
  ingress.#:                                  "" => "<computed>"
  name:                                       "" => "<computed>"
  name_prefix:                                "" => "poi-eks-cluster"
  owner_id:                                   "" => "<computed>"
  revoke_rules_on_delete:                     "" => "false"
  tags.%:                                     "" => "3"
  tags.Environment:                           "" => "poi-eks-env"
  tags.Name:                                  "" => "poi-eks-cluster-eks_worker_sg"
  tags.kubernetes.io/cluster/poi-eks-cluster: "" => "owned"
  vpc_id:                                     "" => "vpc-3842495d"
module.eks.data.aws_iam_policy_document.worker_autoscaling: Refreshing state...
module.eks.data.template_file.kubeconfig: Refreshing state...
module.eks.aws_iam_policy.worker_autoscaling: Creating...
  arn:         "" => "<computed>"
  description: "" => "EKS worker node autoscaling policy for cluster poi-eks-cluster"
  name:        "" => "<computed>"
  name_prefix: "" => "eks-worker-autoscaling-poi-eks-cluster"
  path:        "" => "/"
  policy:      "" => "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"eksWorkerAutoscalingAll\",\n      \"Effect\": \"Allow\",\n      \"Action\
": [\n        \"autoscaling:GetAsgForInstance\",\n        \"autoscaling:DescribeTags\",\n        \"autoscaling:DescribeLaunchConfigurations\",\n        \"autoscaling:Describe
AutoScalingInstances\",\n        \"autoscaling:DescribeAutoScalingGroups\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Sid\": \"eksWorkerAutoscalingOwn\",\n
     \"Effect\": \"Allow\",\n      \"Action\": [\n        \"autoscaling:UpdateAutoScalingGroup\",\n        \"autoscaling:TerminateInstanceInAutoScalingGroup\",\n        \"aut
oscaling:SetDesiredCapacity\"\n      ],\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"autoscaling:ResourceTag/k8s.io/cluster-a
utoscaler/enabled\": \"true\",\n          \"autoscaling:ResourceTag/kubernetes.io/cluster/poi-eks-cluster\": \"owned\"\n        }\n      }\n    }\n  ]\n}"
module.eks.local_file.kubeconfig: Creating...
  content:  "" => "apiVersion: v1\npreferences: {}\nkind: Config\n\nclusters:\n- cluster:\n    server: https://D4DF4DD16049F9E5C09A25BBB6AC88E4.yl4.eu-west-1.eks.amazonaws.co
m\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjR
YRFRFNE1URXhNakUwTlRjMU5Gb1hEVEk0TVRFd09URTBOVGMxTkZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTmtICkpHUVB4ZzR1dDNKM
3ZuWkZvV3RlUnBSaThWVFc2aU9zN0hrYmZ0NktFREY4WUMrQXBnMzd6QWwweGtGTnR0UVQKSzg2M3QrbjhCcVFBVHZucEdpRWhBVWVwZjRScUtPL0dnQldqZjhQYytIUXF6d1NDMjFOY291WlRBaW9IK0VKcwo5ZTU3QVFWdW1Jakt
iSzB6NG9OYlJZSXJxazd6Rjl4UGFBeTNYSzZZOUgvY0FsYlhSbUVCVVp2TnVuaExEMUprCldsK0pQNFc2aXRzMS9OWEUzUU9YYVdEcVNyaTNBV2s0Y3hvdTJENHdzMmVJLzNmRktYTEFNcDIvZkVPOCs3eFIKMm1jWTJXelhNQnd1a
mVNZHBIRk0xZHRrbTBGdk9zZSsvQ2tOb1hpZnF5TTlvdytxSnFwLzU1VkF4V2hBbTBWeQp4bEwvdVBZUU9WSWFpZlFpaWJFQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0R
RWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFIc01tNmFLKzA1MDNEWEtwZ1hmbWpNRVRtdFgKNlN6bk1aZUZvYkZDS0FRSml1bWJES25rUnZOczR2YURSZWE0eGROZ2J1SkxHUzR4MllwWFdXcEh6bmVMRWZTcgpVY2M3ZVFCNVpLcGZ3a
GJGLy9jd3RwRVhaNm9waWRqWGU0RnBZd1FEV0k3aGc5OFY5VXpMeFpYWGQvbE9YRUpZCmxvYVJNSjc0TVZ3Tnd4cmtrMjg3M0N5UHVCTk5MNG80enlna1lHQVNETmxxWlVwc1FnbFZVUjRxMU9UMjd4bXcKVDlROEtjV3JPK2ZjcTV
HMzFpcHNBb2drUi9QSjFJby9XZkxSdXFnL2JYcmhWM255ZHZzNk03MW5MMTM4MHJSKwpOR0NUMW8wMXNJT3BHdmpXWlhjMVJMTi83aDkydmcvUW5DZlJBeWtZekpUQm9JcndhazI5R1pQK2kxZz0KLS0tLS1FTkQgQ0VSVElGSUNBV
EUtLS0tLQo=\n  name: eks_poi-eks-cluster\n\ncontexts:\n- context:\n    cluster: eks_poi-eks-cluster\n    user: eks_poi-eks-cluster\n  name: eks_poi-eks-cluster\n\ncurrent-con
text: eks_poi-eks-cluster\n\nusers:\n- name: eks_poi-eks-cluster\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1alpha1\n      command: aws-iam-authenti
cator\n      args:\n        - \"token\"\n        - \"-i\"\n        - \"poi-eks-cluster\"\n\n\n"
  filename: "" => "./kubeconfig_poi-eks-cluster"
module.eks.local_file.kubeconfig: Creation complete after 0s (ID: d3b3f7595139dfd6234409cd78a396069f9e0de4)
module.eks.aws_iam_policy.worker_autoscaling: Creation complete after 5s (ID: arn:aws:iam::077978206904:policy/eks-wo...-eks-cluster20181112150046927400000007)
module.eks.aws_iam_role.workers: Creation complete after 6s (ID: poi-eks-cluster20181112150046903400000005)
module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly: Creating...
  policy_arn: "" => "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
  role:       "" => "poi-eks-cluster20181112150046903400000005"
module.eks.aws_iam_role_policy_attachment.workers_autoscaling: Creating...
  policy_arn: "" => "arn:aws:iam::077978206904:policy/eks-worker-autoscaling-poi-eks-cluster20181112150046927400000007"
  role:       "" => "poi-eks-cluster20181112150046903400000005"
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy: Creating...
  policy_arn: "" => "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
  role:       "" => "poi-eks-cluster20181112150046903400000005"
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy: Creating...
  policy_arn: "" => "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
  role:       "" => "poi-eks-cluster20181112150046903400000005"
module.eks.aws_iam_instance_profile.workers: Creating...
  arn:         "" => "<computed>"
  create_date: "" => "<computed>"
  name:        "" => "<computed>"
  name_prefix: "" => "poi-eks-cluster"
  path:        "" => "/"
  role:        "" => "poi-eks-cluster20181112150046903400000005"
  roles.#:     "" => "<computed>"
  unique_id:   "" => "<computed>"
module.eks.data.template_file.userdata: Refreshing state...
module.eks.aws_security_group.workers: Creation complete after 10s (ID: sg-0c1068c7530d6a697)
module.eks.aws_security_group_rule.workers_ingress_cluster: Creating...
  description:              "" => "Allow workers Kubelets and pods to receive communication from the cluster control plane."
  from_port:                "" => "1025"
  protocol:                 "" => "tcp"
  security_group_id:        "" => "sg-0c1068c7530d6a697"
  self:                     "" => "false"
  source_security_group_id: "" => "sg-03e51eeeb304dd9b6"
  to_port:                  "" => "65535"
  type:                     "" => "ingress"
module.eks.aws_security_group_rule.workers_ingress_cluster_https: Creating...
  description:              "" => "Allow pods running extension API servers on port 443 to receive communication from cluster control plane."
  from_port:                "" => "443"
  protocol:                 "" => "tcp"
  security_group_id:        "" => "sg-0c1068c7530d6a697"
  self:                     "" => "false"
  source_security_group_id: "" => "sg-03e51eeeb304dd9b6"
  to_port:                  "" => "443"
  type:                     "" => "ingress"
module.eks.aws_security_group_rule.workers_egress_internet: Creating...
  cidr_blocks.#:            "" => "1"
  cidr_blocks.0:            "" => "0.0.0.0/0"
  description:              "" => "Allow nodes all egress to the Internet."
  from_port:                "" => "0"
  protocol:                 "" => "-1"
  security_group_id:        "" => "sg-0c1068c7530d6a697"
  self:                     "" => "false"
  source_security_group_id: "" => "<computed>"
  to_port:                  "" => "0"
  type:                     "" => "egress"
module.eks.aws_security_group_rule.workers_ingress_self: Creating...
  description:              "" => "Allow node to communicate with each other."
  from_port:                "" => "0"
  protocol:                 "" => "-1"
  security_group_id:        "" => "sg-0c1068c7530d6a697"
  self:                     "" => "false"
  source_security_group_id: "" => "sg-0c1068c7530d6a697"
  to_port:                  "" => "65535"
  type:                     "" => "ingress"
module.eks.aws_security_group_rule.cluster_https_worker_ingress: Creating...
  description:              "" => "Allow pods to communicate with the EKS cluster API."
  from_port:                "" => "443"
  protocol:                 "" => "tcp"
  security_group_id:        "" => "sg-03e51eeeb304dd9b6"
  self:                     "" => "false"
  source_security_group_id: "" => "sg-0c1068c7530d6a697"
  to_port:                  "" => "443"
  type:                     "" => "ingress"
module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly: Creation complete after 5s (ID: poi-eks-cluster20181112150046903400000005-20181112150054
744700000009)
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy: Creation complete after 5s (ID: poi-eks-cluster20181112150046903400000005-20181112150054757700000
00a)
module.eks.aws_iam_instance_profile.workers: Creation complete after 5s (ID: poi-eks-cluster20181112150053227000000008)
module.eks.data.template_file.worker_role_arns: Refreshing state...
module.eks.aws_launch_configuration.workers: Creating...
  associate_public_ip_address:               "" => "false"
  ebs_block_device.#:                        "" => "<computed>"
  ebs_optimized:                             "" => "false"
  enable_monitoring:                         "" => "true"
  iam_instance_profile:                      "" => "poi-eks-cluster20181112150053227000000008"
  image_id:                                  "" => "ami-00c3b2d35bddd4f5c"
  instance_type:                             "" => "t2.medium"
  key_name:                                  "" => "<computed>"
  name:                                      "" => "<computed>"
  name_prefix:                               "" => "poi-eks-cluster-0"
  root_block_device.#:                       "" => "1"
  root_block_device.0.delete_on_termination: "" => "true"
  root_block_device.0.iops:                  "" => "0"
  root_block_device.0.volume_size:           "" => "100"
  root_block_device.0.volume_type:           "" => "gp2"
  security_groups.#:                         "" => "1"
  security_groups.2390100246:                "" => "sg-0c1068c7530d6a697"
  user_data_base64:                          "" => "IyEvYmluL2Jhc2ggLXhlCgojIEFsbG93IHVzZXIgc3VwcGxpZWQgcHJlIHVzZXJkYXRhIGNvZGUKCgojIEJvb3RzdHJhcCBhbmQgam9pbiB0aGUgY2x1c3Rlcg
ovZXRjL2Vrcy9ib290c3RyYXAuc2ggLS1iNjQtY2x1c3Rlci1jYSAnTFMwdExTMUNSVWRKVGlCRFJWSlVTVVpKUTBGVVJTMHRMUzB0Q2sxSlNVTjVSRU5EUVdKRFowRjNTVUpCWjBsQ1FVUkJUa0puYTNGb2EybEhPWGN3UWtGUmMw
WkJSRUZXVFZKTmQwVlJXVVJXVVZGRVJYZHdjbVJYU213S1kyMDFiR1JIVm5wTlFqUllSRlJGTkUxVVJYaE5ha1V3VGxSak1VNUdiMWhFVkVrMFRWUkZkMDlVUlRCT1ZHTXhUa1p2ZDBaVVJWUk5Ra1ZIUVRGVlJRcEJlRTFMWVROV2
FWcFlTblZhV0ZKc1kzcERRMEZUU1hkRVVWbEtTMjlhU1doMlkwNUJVVVZDUWxGQlJHZG5SVkJCUkVORFFWRnZRMmRuUlVKQlRtdElDa3BIVVZCNFp6UjFkRE5LTTNadVdrWnZWM1JsVW5CU2FUaFdWRmMyYVU5ek4waHJZbVowTmt0
RlJFWTRXVU1yUVhCbk16ZDZRV3d3ZUd0R1RuUjBVVlFLU3pnMk0zUXJiamhDY1ZGQlZIWnVjRWRwUldoQlZXVndaalJTY1V0UEwwZG5RbGRxWmpoUVl5dElVWEY2ZDFORE1qRk9ZMjkxV2xSQmFXOUlLMFZLY3dvNVpUVTNRVkZXZF
cxSmFrdGlTekI2Tkc5T1lsSlpTWEp4YXpkNlJqbDRVR0ZCZVROWVN6WlpPVWd2WTBGc1lsaFNiVVZDVlZwMlRuVnVhRXhFTVVwckNsZHNLMHBRTkZjMmFYUnpNUzlPV0VVelVVOVlZVmRFY1ZOeWFUTkJWMnMwWTNodmRUSkVOSGR6
TW1WSkx6Tm1Sa3RZVEVGTmNESXZaa1ZQT0NzM2VGSUtNbTFqV1RKWGVsaE5RbmQxYW1WTlpIQklSazB4WkhScmJUQkdkazl6WlNzdlEydE9iMWhwWm5GNVRUbHZkeXR4U25Gd0x6VTFWa0Y0VjJoQmJUQldlUXA0YkV3dmRWQlpVVT
lXU1dGcFpsRnBhV0pGUTBGM1JVRkJZVTFxVFVORmQwUm5XVVJXVWpCUVFWRklMMEpCVVVSQlowdHJUVUU0UjBFeFZXUkZkMFZDQ2k5M1VVWk5RVTFDUVdZNGQwUlJXVXBMYjFwSmFIWmpUa0ZSUlV4Q1VVRkVaMmRGUWtGSWMwMXRO
bUZMS3pBMU1ETkVXRXR3WjFobWJXcE5SVlJ0ZEZnS05sTjZiazFhWlVadllrWkRTMEZSU21sMWJXSkVTMjVyVW5aT2N6UjJZVVJTWldFMGVHUk9aMkoxU2t4SFV6UjRNbGx3V0ZkWGNFaDZibVZNUldaVGNncFZZMk0zWlZGQ05WcE
xjR1ozYUdKR0x5OWpkM1J3UlZoYU5tOXdhV1JxV0dVMFJuQlpkMUZFVjBrM2FHYzVPRlk1VlhwTWVGcFlXR1F2YkU5WVJVcFpDbXh2WVZKTlNqYzBUVlozVG5kNGNtdHJNamczTTBONVVIVkNUazVNTkc4MGVubG5hMWxIUVZORVRt
eHhXbFZ3YzFGbmJGWlZValJ4TVU5VU1qZDRiWGNLVkRsUk9FdGpWM0pQSzJaamNUVkhNekZwY0hOQmIyZHJVaTlRU2pGSmJ5OVhaa3hTZFhGbkwySlljbWhXTTI1NVpIWnpOazAzTVc1TU1UTTRNSEpTS3dwT1IwTlVNVzh3TVhOSl
QzQkhkbXBYV2xoak1WSk1UaTgzYURreWRtY3ZVVzVEWmxKQmVXdFpla3BVUW05SmNuZGhhekk1UjFwUUsya3haejBLTFMwdExTMUZUa1FnUTBWU1ZFbEdTVU5CVkVVdExTMHRMUW89JyAtLWFwaXNlcnZlci1lbmRwb2ludCAnaHR0
cHM6Ly9ENERGNEREMTYwNDlGOUU1QzA5QTI1QkJCNkFDODhFNC55bDQuZXUtd2VzdC0xLmVrcy5hbWF6b25hd3MuY29tJyAtLWt1YmVsZXQtZXh0cmEtYXJncyAnJyAncG9pLWVrcy1jbHVzdGVyJwoKIyBBbGxvdyB1c2VyIHN1cH
BsaWVkIHVzZXJkYXRhIGNvZGUKCg=="
module.eks.data.template_file.config_map_aws_auth: Refreshing state...
module.eks.aws_iam_role_policy_attachment.workers_autoscaling: Creation complete after 5s (ID: poi-eks-cluster20181112150046903400000005-2018111215005480270000000c)
module.eks.local_file.config_map_aws_auth: Creating...
  content:  "" => "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: aws-auth\n  namespace: kube-system\ndata:\n  mapRoles: |\n    - rolearn: arn:aws:iam::077978206904:role
/poi-eks-cluster20181112150046903400000005\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - system:bootstrappers\n        - system:nodes\n\n\n  ma
pUsers: |\n\n  mapAccounts: |\n\n"
  filename: "" => "./config-map-aws-auth_poi-eks-cluster.yaml"
module.eks.local_file.config_map_aws_auth: Creation complete after 0s (ID: 61740f7da860da5e9336e29f337b9f7cb4f45cee)
module.eks.null_resource.update_config_map_aws_auth: Creating...
  triggers.%:                   "" => "1"
  triggers.config_map_rendered: "" => "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: aws-auth\n  namespace: kube-system\ndata:\n  mapRoles: |\n    - rolearn: arn:aws:ia
m::077978206904:role/poi-eks-cluster20181112150046903400000005\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - system:bootstrappers\n        - sy
stem:nodes\n\n\n  mapUsers: |\n\n  mapAccounts: |\n\n"
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy: Creation complete after 5s (ID: poi-eks-cluster20181112150046903400000005-2018111215005478460000000b)
module.eks.null_resource.update_config_map_aws_auth: Provisioning with 'local-exec'...
module.eks.null_resource.update_config_map_aws_auth (local-exec): Executing: ["cmd" "/C" "kubectl apply -f ./config-map-aws-auth_poi-eks-cluster.yaml --kubeconfig ./kubeconfi
g_poi-eks-cluster"]
module.eks.aws_security_group_rule.workers_ingress_cluster: Creation complete after 4s (ID: sgrule-4234145352)
module.eks.aws_security_group_rule.cluster_https_worker_ingress: Creation complete after 4s (ID: sgrule-1332668048)
module.eks.aws_security_group_rule.workers_ingress_cluster_https: Creation complete after 8s (ID: sgrule-3453657617)
module.eks.aws_security_group_rule.workers_egress_internet: Still creating... (10s elapsed)
module.eks.aws_security_group_rule.workers_ingress_self: Still creating... (10s elapsed)
module.eks.aws_launch_configuration.workers: Still creating... (10s elapsed)
module.eks.null_resource.update_config_map_aws_auth: Still creating... (10s elapsed)
module.eks.aws_security_group_rule.workers_egress_internet: Creation complete after 12s (ID: sgrule-1851403480)
module.eks.aws_launch_configuration.workers: Creation complete after 11s (ID: poi-eks-cluster-02018111215010039420000000d)
module.eks.aws_autoscaling_group.workers: Creating...
  arn:                            "" => "<computed>"
  default_cooldown:               "" => "<computed>"
  desired_capacity:               "" => "3"
  force_delete:                   "" => "false"
  health_check_grace_period:      "" => "300"
  health_check_type:              "" => "<computed>"
  launch_configuration:           "" => "poi-eks-cluster-02018111215010039420000000d"
  load_balancers.#:               "" => "<computed>"
  max_size:                       "" => "4"
  metrics_granularity:            "" => "1Minute"
  min_size:                       "" => "1"
  name:                           "" => "<computed>"
  name_prefix:                    "" => "poi-eks-cluster-0"
  protect_from_scale_in:          "" => "false"
  service_linked_role_arn:        "" => "<computed>"
  tags.#:                         "" => "4"
  tags.0.%:                       "" => "3"
  tags.0.key:                     "" => "Name"
  tags.0.propagate_at_launch:     "" => "1"
  tags.0.value:                   "" => "poi-eks-cluster-0-eks_asg"
  tags.1.%:                       "" => "3"
  tags.1.key:                     "" => "kubernetes.io/cluster/poi-eks-cluster"
  tags.1.propagate_at_launch:     "" => "1"
  tags.1.value:                   "" => "owned"
  tags.2.%:                       "" => "3"
  tags.2.key:                     "" => "k8s.io/cluster-autoscaler/disabled"
  tags.2.propagate_at_launch:     "" => "0"
  tags.2.value:                   "" => "true"
  tags.3.%:                       "" => "3"
  tags.3.key:                     "" => "Environment"
  tags.3.propagate_at_launch:     "" => "1"
  tags.3.value:                   "" => "poi-eks-env"
  target_group_arns.#:            "" => "<computed>"
  vpc_zone_identifier.#:          "" => "4"
  vpc_zone_identifier.1004225602: "" => "subnet-a850bce0"
  vpc_zone_identifier.1874057288: "" => "subnet-c11f05b6"
  vpc_zone_identifier.2903397952: "" => "subnet-8813e1ec"
  vpc_zone_identifier.3978819587: "" => "subnet-a3685afa"
  wait_for_capacity_timeout:      "" => "10m"
module.eks.aws_security_group_rule.workers_ingress_self: Creation complete after 16s (ID: sgrule-104457586)
module.eks.null_resource.update_config_map_aws_auth (local-exec): configmap "aws-auth" created
module.eks.null_resource.update_config_map_aws_auth: Creation complete after 19s (ID: 6723567334385867812)
module.eks.aws_autoscaling_group.workers: Still creating... (10s elapsed)
module.eks.aws_autoscaling_group.workers: Still creating... (20s elapsed)
module.eks.aws_autoscaling_group.workers: Still creating... (30s elapsed)
module.eks.aws_autoscaling_group.workers: Still creating... (40s elapsed)
module.eks.aws_autoscaling_group.workers: Creation complete after 49s (ID: poi-eks-cluster-02018111215010884090000000e)

Apply complete! Resources: 25 added, 0 changed, 0 destroyed.
PS C:\DDrive\MyData\Yogesh\git_repo\DevOps\kubernetes\aws-eks> kubectl --kubeconfig .\kubeconfig_poi-eks-cluster get nodes
NAME                                           STATUS    ROLES     AGE       VERSION
ip-172-29-118-146.eu-west-1.compute.internal   Ready     <none>    2m        v1.10.3
ip-172-29-119-45.eu-west-1.compute.internal    Ready     <none>    2m        v1.10.3
ip-172-29-226-220.eu-west-1.compute.internal   Ready     <none>    2m        v1.10.3
PS C:\DDrive\MyData\Yogesh\git_repo\DevOps\kubernetes\aws-eks> kubectl --kubeconfig .\kubeconfig_poi-eks-cluster get services
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.100.0.1   <none>        443/TCP   5m
PS C:\DDrive\MyData\Yogesh\git_repo\DevOps\kubernetes\aws-eks> terraform destroy