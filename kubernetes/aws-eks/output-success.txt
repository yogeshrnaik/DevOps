PS C:\DDrive\MyData\Yogesh\git_repo\DevOps\kubernetes\aws-eks> terraform plan
Refreshing Terraform state in-memory prior to plan...
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.

data.aws_region.current: Refreshing state...
data.aws_caller_identity.current: Refreshing state...
data.aws_iam_policy_document.workers_assume_role_policy: Refreshing state...
data.aws_ami.eks_worker: Refreshing state...
data.aws_iam_policy_document.cluster_assume_role_policy: Refreshing state...

------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

 <= module.eks.data.aws_iam_policy_document.worker_autoscaling
      id:                                                 <computed>
      json:                                               <computed>
      statement.#:                                        "2"
      statement.0.actions.#:                              "5"
      statement.0.actions.1274732150:                     "autoscaling:DescribeAutoScalingGroups"
      statement.0.actions.2448883636:                     "autoscaling:DescribeAutoScalingInstances"
      statement.0.actions.2555065653:                     "autoscaling:DescribeLaunchConfigurations"
      statement.0.actions.3701464416:                     "autoscaling:DescribeTags"
      statement.0.actions.4281419483:                     "autoscaling:GetAsgForInstance"
      statement.0.effect:                                 "Allow"
      statement.0.resources.#:                            "1"
      statement.0.resources.2679715827:                   "*"
      statement.0.sid:                                    "eksWorkerAutoscalingAll"
      statement.1.actions.#:                              "3"
      statement.1.actions.1536675971:                     "autoscaling:UpdateAutoScalingGroup"
      statement.1.actions.3469696720:                     "autoscaling:TerminateInstanceInAutoScalingGroup"
      statement.1.actions.557626329:                      "autoscaling:SetDesiredCapacity"
      statement.1.condition.#:                            "2"
      statement.1.condition.3636405986.test:              "StringEquals"
      statement.1.condition.3636405986.values.#:          "1"
      statement.1.condition.3636405986.values.4043113848: "true"
      statement.1.condition.3636405986.variable:          "autoscaling:ResourceTag/k8s.io/cluster-autoscaler/enabled"
      statement.1.condition.4028998177.test:              "StringEquals"
      statement.1.condition.4028998177.values.#:          "1"
      statement.1.condition.4028998177.values.653127311:  "owned"
      statement.1.condition.4028998177.variable:          "autoscaling:ResourceTag/kubernetes.io/cluster/poi-eks-cluster"
      statement.1.effect:                                 "Allow"
      statement.1.resources.#:                            "1"
      statement.1.resources.2679715827:                   "*"
      statement.1.sid:                                    "eksWorkerAutoscalingOwn"

 <= module.eks.data.template_file.config_map_aws_auth
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: aws-auth\n  namespace: kube-system\ndata:\n  mapRoles: |\n${wor
ker_role_arn}\n${map_roles}\n  mapUsers: |\n${map_users}\n  mapAccounts: |\n${map_accounts}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.kubeconfig
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "apiVersion: v1\npreferences: {}\nkind: Config\n\nclusters:\n- cluster:\n    server: ${endpoint}\n    certificate-au
thority-data: ${cluster_auth_base64}\n  name: ${kubeconfig_name}\n\ncontexts:\n- context:\n    cluster: ${kubeconfig_name}\n    user: ${kubeconfig_name}\n  name: ${kubeconfig
_name}\n\ncurrent-context: ${kubeconfig_name}\n\nusers:\n- name: ${kubeconfig_name}\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1alpha1\n      comman
d: ${aws_authenticator_command}\n      args:\n        - \"token\"\n        - \"-i\"\n        - \"${cluster_name}\"\n${aws_authenticator_additional_args}\n${aws_authenticator_
env_variables}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.userdata[0]
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "#!/bin/bash -xe\n\n# Allow user supplied pre userdata code\n${pre_userdata}\n\n# Bootstrap and join the cluster\n/e
tc/eks/bootstrap.sh --b64-cluster-ca '${cluster_auth_base64}' --apiserver-endpoint '${endpoint}' --kubelet-extra-args '${kubelet_extra_args}' '${cluster_name}'\n\n# Allow use
r supplied userdata code\n${additional_userdata}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.userdata[1]
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "#!/bin/bash -xe\n\n# Allow user supplied pre userdata code\n${pre_userdata}\n\n# Bootstrap and join the cluster\n/e
tc/eks/bootstrap.sh --b64-cluster-ca '${cluster_auth_base64}' --apiserver-endpoint '${endpoint}' --kubelet-extra-args '${kubelet_extra_args}' '${cluster_name}'\n\n# Allow use
r supplied userdata code\n${additional_userdata}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.worker_role_arns[0]
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "    - rolearn: ${worker_role_arn}\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - syst
em:bootstrappers\n        - system:nodes\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.worker_role_arns[1]
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "    - rolearn: ${worker_role_arn}\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - syst
em:bootstrappers\n        - system:nodes\n"
      vars.%:                                             <computed>

  + module.eks.aws_autoscaling_group.workers[0]
      id:                                                 <computed>
      arn:                                                <computed>
      availability_zones.#:                               <computed>
      default_cooldown:                                   <computed>
      desired_capacity:                                   "0"
      force_delete:                                       "false"
      health_check_grace_period:                          "300"
      health_check_type:                                  <computed>
      launch_configuration:                               "${element(aws_launch_configuration.workers.*.id, count.index)}"
      load_balancers.#:                                   <computed>
      max_size:                                           "0"
      metrics_granularity:                                "1Minute"
      min_size:                                           "0"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-0"
      protect_from_scale_in:                              "false"
      service_linked_role_arn:                            <computed>
      tags.#:                                             <computed>
      target_group_arns.#:                                <computed>
      vpc_zone_identifier.#:                              <computed>
      wait_for_capacity_timeout:                          "10m"

  + module.eks.aws_autoscaling_group.workers[1]
      id:                                                 <computed>
      arn:                                                <computed>
      availability_zones.#:                               <computed>
      default_cooldown:                                   <computed>
      desired_capacity:                                   "0"
      force_delete:                                       "false"
      health_check_grace_period:                          "300"
      health_check_type:                                  <computed>
      launch_configuration:                               "${element(aws_launch_configuration.workers.*.id, count.index)}"
      load_balancers.#:                                   <computed>
      max_size:                                           "0"
      metrics_granularity:                                "1Minute"
      min_size:                                           "0"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-1"
      protect_from_scale_in:                              "false"
      service_linked_role_arn:                            <computed>
      tags.#:                                             <computed>
      target_group_arns.#:                                <computed>
      vpc_zone_identifier.#:                              <computed>
      wait_for_capacity_timeout:                          "10m"

  + module.eks.aws_eks_cluster.this
      id:                                                 <computed>
      arn:                                                <computed>
      certificate_authority.#:                            <computed>
      created_at:                                         <computed>
      endpoint:                                           <computed>
      name:                                               "poi-eks-cluster"
      platform_version:                                   <computed>
      role_arn:                                           "${aws_iam_role.cluster.arn}"
      version:                                            "1.10"
      vpc_config.#:                                       "1"
      vpc_config.0.security_group_ids.#:                  <computed>
      vpc_config.0.subnet_ids.#:                          "4"
      vpc_config.0.subnet_ids.360204655:                  "subnet-8813e1ec"
      vpc_config.0.subnet_ids.4209864939:                 "subnet-a3685afa"
      vpc_config.0.subnet_ids.4225826129:                 "subnet-a850bce0"
      vpc_config.0.subnet_ids.459373779:                  "subnet-c11f05b6"
      vpc_config.0.vpc_id:                                <computed>

  + module.eks.aws_iam_instance_profile.workers[0]
      id:                                                 <computed>
      arn:                                                <computed>
      create_date:                                        <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      role:                                               "${lookup(var.worker_groups[count.index], \"iam_role_id\",  lookup(local.workers_group_defaults, \"iam_role_id\"))}"
      roles.#:                                            <computed>
      unique_id:                                          <computed>

  + module.eks.aws_iam_instance_profile.workers[1]
      id:                                                 <computed>
      arn:                                                <computed>
      create_date:                                        <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      role:                                               "${lookup(var.worker_groups[count.index], \"iam_role_id\",  lookup(local.workers_group_defaults, \"iam_role_id\"))}"
      roles.#:                                            <computed>
      unique_id:                                          <computed>

  + module.eks.aws_iam_policy.worker_autoscaling
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "EKS worker node autoscaling policy for cluster poi-eks-cluster"
      name:                                               <computed>
      name_prefix:                                        "eks-worker-autoscaling-poi-eks-cluster"
      path:                                               "/"
      policy:                                             "${data.aws_iam_policy_document.worker_autoscaling.json}"

  + module.eks.aws_iam_role.cluster
      id:                                                 <computed>
      arn:                                                <computed>
      assume_role_policy:                                 "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSClusterAssumeRole\",\n      \"Eff
ect\": \"Allow\",\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"eks.amazonaws.com\"\n      }\n    }\n  ]\n}"
      create_date:                                        <computed>
      force_detach_policies:                              "false"
      max_session_duration:                               "3600"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      unique_id:                                          <computed>

  + module.eks.aws_iam_role.workers
      id:                                                 <computed>
      arn:                                                <computed>
      assume_role_policy:                                 "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSWorkerAssumeRole\",\n      \"Effe
ct\": \"Allow\",\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      }\n    }\n  ]\n}"
      create_date:                                        <computed>
      force_detach_policies:                              "false"
      max_session_duration:                               "3600"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      unique_id:                                          <computed>

  + module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
      role:                                               "${aws_iam_role.cluster.name}"

  + module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSServicePolicy"
      role:                                               "${aws_iam_role.cluster.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_autoscaling
      id:                                                 <computed>
      policy_arn:                                         "${aws_iam_policy.worker_autoscaling.arn}"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_launch_configuration.workers[0]
      id:                                                 <computed>
      associate_public_ip_address:                        "false"
      ebs_block_device.#:                                 <computed>
      ebs_optimized:                                      "false"
      enable_monitoring:                                  "false"
      iam_instance_profile:                               "${element(aws_iam_instance_profile.workers.*.id, count.index)}"
      image_id:                                           "${lookup(var.worker_groups[count.index], \"ami_id\", local.workers_group_defaults[\"ami_id\"])}"
      instance_type:                                      "${lookup(var.worker_groups[count.index], \"instance_type\", local.workers_group_defaults[\"instance_type\"])}"
      key_name:                                           "${lookup(var.worker_groups[count.index], \"key_name\", local.workers_group_defaults[\"key_name\"])}"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-0"
      placement_tenancy:                                  "${lookup(var.worker_groups[count.index], \"placement_tenancy\", local.workers_group_defaults[\"placement_tenancy\"]
)}"
      root_block_device.#:                                "1"
      root_block_device.0.delete_on_termination:          "true"
      root_block_device.0.iops:                           "0"
      root_block_device.0.volume_size:                    "0"
      root_block_device.0.volume_type:                    "${lookup(var.worker_groups[count.index], \"root_volume_type\", local.workers_group_defaults[\"root_volume_type\"])}
"
      security_groups.#:                                  <computed>
      spot_price:                                         "${lookup(var.worker_groups[count.index], \"spot_price\", local.workers_group_defaults[\"spot_price\"])}"
      user_data_base64:                                   "${base64encode(element(data.template_file.userdata.*.rendered, count.index))}"

  + module.eks.aws_launch_configuration.workers[1]
      id:                                                 <computed>
      associate_public_ip_address:                        "false"
      ebs_block_device.#:                                 <computed>
      ebs_optimized:                                      "false"
      enable_monitoring:                                  "false"
      iam_instance_profile:                               "${element(aws_iam_instance_profile.workers.*.id, count.index)}"
      image_id:                                           "${lookup(var.worker_groups[count.index], \"ami_id\", local.workers_group_defaults[\"ami_id\"])}"
      instance_type:                                      "${lookup(var.worker_groups[count.index], \"instance_type\", local.workers_group_defaults[\"instance_type\"])}"
      key_name:                                           "${lookup(var.worker_groups[count.index], \"key_name\", local.workers_group_defaults[\"key_name\"])}"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-1"
      placement_tenancy:                                  "${lookup(var.worker_groups[count.index], \"placement_tenancy\", local.workers_group_defaults[\"placement_tenancy\"]
)}"
      root_block_device.#:                                "1"
      root_block_device.0.delete_on_termination:          "true"
      root_block_device.0.iops:                           "0"
      root_block_device.0.volume_size:                    "0"
      root_block_device.0.volume_type:                    "${lookup(var.worker_groups[count.index], \"root_volume_type\", local.workers_group_defaults[\"root_volume_type\"])}
"
      security_groups.#:                                  <computed>
      spot_price:                                         "${lookup(var.worker_groups[count.index], \"spot_price\", local.workers_group_defaults[\"spot_price\"])}"
      user_data_base64:                                   "${base64encode(element(data.template_file.userdata.*.rendered, count.index))}"

  + module.eks.aws_security_group.cluster
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "EKS cluster security group."
      egress.#:                                           <computed>
      ingress.#:                                          <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      owner_id:                                           <computed>
      revoke_rules_on_delete:                             "false"
      tags.%:                                             "2"
      tags.Environment:                                   "poi-eks-env"
      tags.Name:                                          "poi-eks-cluster-eks_cluster_sg"
      vpc_id:                                             "vpc-3842495d"

  + module.eks.aws_security_group.workers
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "Security group for all nodes in the cluster."
      egress.#:                                           <computed>
      ingress.#:                                          <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      owner_id:                                           <computed>
      revoke_rules_on_delete:                             "false"
      tags.%:                                             "3"
      tags.Environment:                                   "poi-eks-env"
      tags.Name:                                          "poi-eks-cluster-eks_worker_sg"
      tags.kubernetes.io/cluster/poi-eks-cluster:         "owned"
      vpc_id:                                             "vpc-3842495d"

  + module.eks.aws_security_group_rule.cluster_egress_internet
      id:                                                 <computed>
      cidr_blocks.#:                                      "1"
      cidr_blocks.0:                                      "0.0.0.0/0"
      description:                                        "Allow cluster egress access to the Internet."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.cluster.id}"
      self:                                               "false"
      source_security_group_id:                           <computed>
      to_port:                                            "0"
      type:                                               "egress"

  + module.eks.aws_security_group_rule.cluster_https_worker_ingress
      id:                                                 <computed>
      description:                                        "Allow pods to communicate with the EKS cluster API."
      from_port:                                          "443"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.cluster.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.worker_security_group_id}"
      to_port:                                            "443"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_egress_internet
      id:                                                 <computed>
      cidr_blocks.#:                                      "1"
      cidr_blocks.0:                                      "0.0.0.0/0"
      description:                                        "Allow nodes all egress to the Internet."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           <computed>
      to_port:                                            "0"
      type:                                               "egress"

  + module.eks.aws_security_group_rule.workers_ingress_cluster
      id:                                                 <computed>
      description:                                        "Allow workers Kubelets and pods to receive communication from the cluster control plane."
      from_port:                                          "1025"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.cluster_security_group_id}"
      to_port:                                            "65535"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_ingress_cluster_https
      id:                                                 <computed>
      description:                                        "Allow pods running extension API servers on port 443 to receive communication from cluster control plane."
      from_port:                                          "443"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.cluster_security_group_id}"
      to_port:                                            "443"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_ingress_self
      id:                                                 <computed>
      description:                                        "Allow node to communicate with each other."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${aws_security_group.workers.id}"
      to_port:                                            "65535"
      type:                                               "ingress"

  + module.eks.local_file.config_map_aws_auth
      id:                                                 <computed>
      content:                                            "${data.template_file.config_map_aws_auth.rendered}"
      filename:                                           "./config-map-aws-auth_poi-eks-cluster.yaml"

  + module.eks.local_file.kubeconfig
      id:                                                 <computed>
      content:                                            "${data.template_file.kubeconfig.rendered}"
      filename:                                           "./kubeconfig_poi-eks-cluster"

  + module.eks.null_resource.tags_as_list_of_maps
      id:                                                 <computed>
      triggers.%:                                         "3"
      triggers.key:                                       "Environment"
      triggers.propagate_at_launch:                       "true"
      triggers.value:                                     "poi-eks-env"

  + module.eks.null_resource.update_config_map_aws_auth
      id:                                                 <computed>
      triggers.%:                                         <computed>


Plan: 28 to add, 0 to change, 0 to destroy.

------------------------------------------------------------------------

Note: You didn't specify an "-out" parameter to save this plan, so Terraform
can't guarantee that exactly these actions will be performed if
"terraform apply" is subsequently run.

PS C:\DDrive\MyData\Yogesh\git_repo\DevOps\kubernetes\aws-eks> terraform apply
data.aws_caller_identity.current: Refreshing state...
data.aws_region.current: Refreshing state...
data.aws_iam_policy_document.workers_assume_role_policy: Refreshing state...
data.aws_iam_policy_document.cluster_assume_role_policy: Refreshing state...
data.aws_ami.eks_worker: Refreshing state...

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

 <= module.eks.data.aws_iam_policy_document.worker_autoscaling
      id:                                                 <computed>
      json:                                               <computed>
      statement.#:                                        "2"
      statement.0.actions.#:                              "5"
      statement.0.actions.1274732150:                     "autoscaling:DescribeAutoScalingGroups"
      statement.0.actions.2448883636:                     "autoscaling:DescribeAutoScalingInstances"
      statement.0.actions.2555065653:                     "autoscaling:DescribeLaunchConfigurations"
      statement.0.actions.3701464416:                     "autoscaling:DescribeTags"
      statement.0.actions.4281419483:                     "autoscaling:GetAsgForInstance"
      statement.0.effect:                                 "Allow"
      statement.0.resources.#:                            "1"
      statement.0.resources.2679715827:                   "*"
      statement.0.sid:                                    "eksWorkerAutoscalingAll"
      statement.1.actions.#:                              "3"
      statement.1.actions.1536675971:                     "autoscaling:UpdateAutoScalingGroup"
      statement.1.actions.3469696720:                     "autoscaling:TerminateInstanceInAutoScalingGroup"
      statement.1.actions.557626329:                      "autoscaling:SetDesiredCapacity"
      statement.1.condition.#:                            "2"
      statement.1.condition.3636405986.test:              "StringEquals"
      statement.1.condition.3636405986.values.#:          "1"
      statement.1.condition.3636405986.values.4043113848: "true"
      statement.1.condition.3636405986.variable:          "autoscaling:ResourceTag/k8s.io/cluster-autoscaler/enabled"
      statement.1.condition.4028998177.test:              "StringEquals"
      statement.1.condition.4028998177.values.#:          "1"
      statement.1.condition.4028998177.values.653127311:  "owned"
      statement.1.condition.4028998177.variable:          "autoscaling:ResourceTag/kubernetes.io/cluster/poi-eks-cluster"
      statement.1.effect:                                 "Allow"
      statement.1.resources.#:                            "1"
      statement.1.resources.2679715827:                   "*"
      statement.1.sid:                                    "eksWorkerAutoscalingOwn"

 <= module.eks.data.template_file.config_map_aws_auth
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: aws-auth\n  namespace: kube-system\ndata:\n  mapRoles: |\n${wor
ker_role_arn}\n${map_roles}\n  mapUsers: |\n${map_users}\n  mapAccounts: |\n${map_accounts}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.kubeconfig
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "apiVersion: v1\npreferences: {}\nkind: Config\n\nclusters:\n- cluster:\n    server: ${endpoint}\n    certificate-au
thority-data: ${cluster_auth_base64}\n  name: ${kubeconfig_name}\n\ncontexts:\n- context:\n    cluster: ${kubeconfig_name}\n    user: ${kubeconfig_name}\n  name: ${kubeconfig
_name}\n\ncurrent-context: ${kubeconfig_name}\n\nusers:\n- name: ${kubeconfig_name}\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1alpha1\n      comman
d: ${aws_authenticator_command}\n      args:\n        - \"token\"\n        - \"-i\"\n        - \"${cluster_name}\"\n${aws_authenticator_additional_args}\n${aws_authenticator_
env_variables}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.userdata[0]
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "#!/bin/bash -xe\n\n# Allow user supplied pre userdata code\n${pre_userdata}\n\n# Bootstrap and join the cluster\n/e
tc/eks/bootstrap.sh --b64-cluster-ca '${cluster_auth_base64}' --apiserver-endpoint '${endpoint}' --kubelet-extra-args '${kubelet_extra_args}' '${cluster_name}'\n\n# Allow use
r supplied userdata code\n${additional_userdata}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.userdata[1]
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "#!/bin/bash -xe\n\n# Allow user supplied pre userdata code\n${pre_userdata}\n\n# Bootstrap and join the cluster\n/e
tc/eks/bootstrap.sh --b64-cluster-ca '${cluster_auth_base64}' --apiserver-endpoint '${endpoint}' --kubelet-extra-args '${kubelet_extra_args}' '${cluster_name}'\n\n# Allow use
r supplied userdata code\n${additional_userdata}\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.worker_role_arns[0]
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "    - rolearn: ${worker_role_arn}\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - syst
em:bootstrappers\n        - system:nodes\n"
      vars.%:                                             <computed>

 <= module.eks.data.template_file.worker_role_arns[1]
      id:                                                 <computed>
      rendered:                                           <computed>
      template:                                           "    - rolearn: ${worker_role_arn}\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - syst
em:bootstrappers\n        - system:nodes\n"
      vars.%:                                             <computed>

  + module.eks.aws_autoscaling_group.workers[0]
      id:                                                 <computed>
      arn:                                                <computed>
      availability_zones.#:                               <computed>
      default_cooldown:                                   <computed>
      desired_capacity:                                   "0"
      force_delete:                                       "false"
      health_check_grace_period:                          "300"
      health_check_type:                                  <computed>
      launch_configuration:                               "${element(aws_launch_configuration.workers.*.id, count.index)}"
      load_balancers.#:                                   <computed>
      max_size:                                           "0"
      metrics_granularity:                                "1Minute"
      min_size:                                           "0"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-0"
      protect_from_scale_in:                              "false"
      service_linked_role_arn:                            <computed>
      tags.#:                                             <computed>
      target_group_arns.#:                                <computed>
      vpc_zone_identifier.#:                              <computed>
      wait_for_capacity_timeout:                          "10m"

  + module.eks.aws_autoscaling_group.workers[1]
      id:                                                 <computed>
      arn:                                                <computed>
      availability_zones.#:                               <computed>
      default_cooldown:                                   <computed>
      desired_capacity:                                   "0"
      force_delete:                                       "false"
      health_check_grace_period:                          "300"
      health_check_type:                                  <computed>
      launch_configuration:                               "${element(aws_launch_configuration.workers.*.id, count.index)}"
      load_balancers.#:                                   <computed>
      max_size:                                           "0"
      metrics_granularity:                                "1Minute"
      min_size:                                           "0"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-1"
      protect_from_scale_in:                              "false"
      service_linked_role_arn:                            <computed>
      tags.#:                                             <computed>
      target_group_arns.#:                                <computed>
      vpc_zone_identifier.#:                              <computed>
      wait_for_capacity_timeout:                          "10m"

  + module.eks.aws_eks_cluster.this
      id:                                                 <computed>
      arn:                                                <computed>
      certificate_authority.#:                            <computed>
      created_at:                                         <computed>
      endpoint:                                           <computed>
      name:                                               "poi-eks-cluster"
      platform_version:                                   <computed>
      role_arn:                                           "${aws_iam_role.cluster.arn}"
      version:                                            "1.10"
      vpc_config.#:                                       "1"
      vpc_config.0.security_group_ids.#:                  <computed>
      vpc_config.0.subnet_ids.#:                          "4"
      vpc_config.0.subnet_ids.360204655:                  "subnet-8813e1ec"
      vpc_config.0.subnet_ids.4209864939:                 "subnet-a3685afa"
      vpc_config.0.subnet_ids.4225826129:                 "subnet-a850bce0"
      vpc_config.0.subnet_ids.459373779:                  "subnet-c11f05b6"
      vpc_config.0.vpc_id:                                <computed>

  + module.eks.aws_iam_instance_profile.workers[0]
      id:                                                 <computed>
      arn:                                                <computed>
      create_date:                                        <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      role:                                               "${lookup(var.worker_groups[count.index], \"iam_role_id\",  lookup(local.workers_group_defaults, \"iam_role_id\"))}"
      roles.#:                                            <computed>
      unique_id:                                          <computed>

  + module.eks.aws_iam_instance_profile.workers[1]
      id:                                                 <computed>
      arn:                                                <computed>
      create_date:                                        <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      role:                                               "${lookup(var.worker_groups[count.index], \"iam_role_id\",  lookup(local.workers_group_defaults, \"iam_role_id\"))}"
      roles.#:                                            <computed>
      unique_id:                                          <computed>

  + module.eks.aws_iam_policy.worker_autoscaling
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "EKS worker node autoscaling policy for cluster poi-eks-cluster"
      name:                                               <computed>
      name_prefix:                                        "eks-worker-autoscaling-poi-eks-cluster"
      path:                                               "/"
      policy:                                             "${data.aws_iam_policy_document.worker_autoscaling.json}"

  + module.eks.aws_iam_role.cluster
      id:                                                 <computed>
      arn:                                                <computed>
      assume_role_policy:                                 "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSClusterAssumeRole\",\n      \"Eff
ect\": \"Allow\",\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"eks.amazonaws.com\"\n      }\n    }\n  ]\n}"
      create_date:                                        <computed>
      force_detach_policies:                              "false"
      max_session_duration:                               "3600"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      unique_id:                                          <computed>

  + module.eks.aws_iam_role.workers
      id:                                                 <computed>
      arn:                                                <computed>
      assume_role_policy:                                 "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSWorkerAssumeRole\",\n      \"Effe
ct\": \"Allow\",\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      }\n    }\n  ]\n}"
      create_date:                                        <computed>
      force_detach_policies:                              "false"
      max_session_duration:                               "3600"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      path:                                               "/"
      unique_id:                                          <computed>

  + module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
      role:                                               "${aws_iam_role.cluster.name}"

  + module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSServicePolicy"
      role:                                               "${aws_iam_role.cluster.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy
      id:                                                 <computed>
      policy_arn:                                         "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_iam_role_policy_attachment.workers_autoscaling
      id:                                                 <computed>
      policy_arn:                                         "${aws_iam_policy.worker_autoscaling.arn}"
      role:                                               "${aws_iam_role.workers.name}"

  + module.eks.aws_launch_configuration.workers[0]
      id:                                                 <computed>
      associate_public_ip_address:                        "false"
      ebs_block_device.#:                                 <computed>
      ebs_optimized:                                      "false"
      enable_monitoring:                                  "false"
      iam_instance_profile:                               "${element(aws_iam_instance_profile.workers.*.id, count.index)}"
      image_id:                                           "${lookup(var.worker_groups[count.index], \"ami_id\", local.workers_group_defaults[\"ami_id\"])}"
      instance_type:                                      "${lookup(var.worker_groups[count.index], \"instance_type\", local.workers_group_defaults[\"instance_type\"])}"
      key_name:                                           "${lookup(var.worker_groups[count.index], \"key_name\", local.workers_group_defaults[\"key_name\"])}"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-0"
      placement_tenancy:                                  "${lookup(var.worker_groups[count.index], \"placement_tenancy\", local.workers_group_defaults[\"placement_tenancy\"]
)}"
      root_block_device.#:                                "1"
      root_block_device.0.delete_on_termination:          "true"
      root_block_device.0.iops:                           "0"
      root_block_device.0.volume_size:                    "0"
      root_block_device.0.volume_type:                    "${lookup(var.worker_groups[count.index], \"root_volume_type\", local.workers_group_defaults[\"root_volume_type\"])}
"
      security_groups.#:                                  <computed>
      spot_price:                                         "${lookup(var.worker_groups[count.index], \"spot_price\", local.workers_group_defaults[\"spot_price\"])}"
      user_data_base64:                                   "${base64encode(element(data.template_file.userdata.*.rendered, count.index))}"

  + module.eks.aws_launch_configuration.workers[1]
      id:                                                 <computed>
      associate_public_ip_address:                        "false"
      ebs_block_device.#:                                 <computed>
      ebs_optimized:                                      "false"
      enable_monitoring:                                  "false"
      iam_instance_profile:                               "${element(aws_iam_instance_profile.workers.*.id, count.index)}"
      image_id:                                           "${lookup(var.worker_groups[count.index], \"ami_id\", local.workers_group_defaults[\"ami_id\"])}"
      instance_type:                                      "${lookup(var.worker_groups[count.index], \"instance_type\", local.workers_group_defaults[\"instance_type\"])}"
      key_name:                                           "${lookup(var.worker_groups[count.index], \"key_name\", local.workers_group_defaults[\"key_name\"])}"
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster-1"
      placement_tenancy:                                  "${lookup(var.worker_groups[count.index], \"placement_tenancy\", local.workers_group_defaults[\"placement_tenancy\"]
)}"
      root_block_device.#:                                "1"
      root_block_device.0.delete_on_termination:          "true"
      root_block_device.0.iops:                           "0"
      root_block_device.0.volume_size:                    "0"
      root_block_device.0.volume_type:                    "${lookup(var.worker_groups[count.index], \"root_volume_type\", local.workers_group_defaults[\"root_volume_type\"])}
"
      security_groups.#:                                  <computed>
      spot_price:                                         "${lookup(var.worker_groups[count.index], \"spot_price\", local.workers_group_defaults[\"spot_price\"])}"
      user_data_base64:                                   "${base64encode(element(data.template_file.userdata.*.rendered, count.index))}"

  + module.eks.aws_security_group.cluster
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "EKS cluster security group."
      egress.#:                                           <computed>
      ingress.#:                                          <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      owner_id:                                           <computed>
      revoke_rules_on_delete:                             "false"
      tags.%:                                             "2"
      tags.Environment:                                   "poi-eks-env"
      tags.Name:                                          "poi-eks-cluster-eks_cluster_sg"
      vpc_id:                                             "vpc-3842495d"

  + module.eks.aws_security_group.workers
      id:                                                 <computed>
      arn:                                                <computed>
      description:                                        "Security group for all nodes in the cluster."
      egress.#:                                           <computed>
      ingress.#:                                          <computed>
      name:                                               <computed>
      name_prefix:                                        "poi-eks-cluster"
      owner_id:                                           <computed>
      revoke_rules_on_delete:                             "false"
      tags.%:                                             "3"
      tags.Environment:                                   "poi-eks-env"
      tags.Name:                                          "poi-eks-cluster-eks_worker_sg"
      tags.kubernetes.io/cluster/poi-eks-cluster:         "owned"
      vpc_id:                                             "vpc-3842495d"

  + module.eks.aws_security_group_rule.cluster_egress_internet
      id:                                                 <computed>
      cidr_blocks.#:                                      "1"
      cidr_blocks.0:                                      "0.0.0.0/0"
      description:                                        "Allow cluster egress access to the Internet."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.cluster.id}"
      self:                                               "false"
      source_security_group_id:                           <computed>
      to_port:                                            "0"
      type:                                               "egress"

  + module.eks.aws_security_group_rule.cluster_https_worker_ingress
      id:                                                 <computed>
      description:                                        "Allow pods to communicate with the EKS cluster API."
      from_port:                                          "443"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.cluster.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.worker_security_group_id}"
      to_port:                                            "443"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_egress_internet
      id:                                                 <computed>
      cidr_blocks.#:                                      "1"
      cidr_blocks.0:                                      "0.0.0.0/0"
      description:                                        "Allow nodes all egress to the Internet."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           <computed>
      to_port:                                            "0"
      type:                                               "egress"

  + module.eks.aws_security_group_rule.workers_ingress_cluster
      id:                                                 <computed>
      description:                                        "Allow workers Kubelets and pods to receive communication from the cluster control plane."
      from_port:                                          "1025"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.cluster_security_group_id}"
      to_port:                                            "65535"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_ingress_cluster_https
      id:                                                 <computed>
      description:                                        "Allow pods running extension API servers on port 443 to receive communication from cluster control plane."
      from_port:                                          "443"
      protocol:                                           "tcp"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${local.cluster_security_group_id}"
      to_port:                                            "443"
      type:                                               "ingress"

  + module.eks.aws_security_group_rule.workers_ingress_self
      id:                                                 <computed>
      description:                                        "Allow node to communicate with each other."
      from_port:                                          "0"
      protocol:                                           "-1"
      security_group_id:                                  "${aws_security_group.workers.id}"
      self:                                               "false"
      source_security_group_id:                           "${aws_security_group.workers.id}"
      to_port:                                            "65535"
      type:                                               "ingress"

  + module.eks.local_file.config_map_aws_auth
      id:                                                 <computed>
      content:                                            "${data.template_file.config_map_aws_auth.rendered}"
      filename:                                           "./config-map-aws-auth_poi-eks-cluster.yaml"

  + module.eks.local_file.kubeconfig
      id:                                                 <computed>
      content:                                            "${data.template_file.kubeconfig.rendered}"
      filename:                                           "./kubeconfig_poi-eks-cluster"

  + module.eks.null_resource.tags_as_list_of_maps
      id:                                                 <computed>
      triggers.%:                                         "3"
      triggers.key:                                       "Environment"
      triggers.propagate_at_launch:                       "true"
      triggers.value:                                     "poi-eks-env"

  + module.eks.null_resource.update_config_map_aws_auth
      id:                                                 <computed>
      triggers.%:                                         <computed>


Plan: 28 to add, 0 to change, 0 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

module.eks.null_resource.tags_as_list_of_maps: Creating...
  triggers.%:                   "" => "3"
  triggers.key:                 "" => "Environment"
  triggers.propagate_at_launch: "" => "true"
  triggers.value:               "" => "poi-eks-env"
module.eks.null_resource.tags_as_list_of_maps: Creation complete after 0s (ID: 1363439499390715014)
module.eks.aws_iam_role.cluster: Creating...
  arn:                   "" => "<computed>"
  assume_role_policy:    "" => "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSClusterAssumeRole\",\n      \"Effect\": \"Allow\",\n      \"
Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"eks.amazonaws.com\"\n      }\n    }\n  ]\n}"
  create_date:           "" => "<computed>"
  force_detach_policies: "" => "false"
  max_session_duration:  "" => "3600"
  name:                  "" => "<computed>"
  name_prefix:           "" => "poi-eks-cluster"
  path:                  "" => "/"
  unique_id:             "" => "<computed>"
module.eks.aws_security_group.cluster: Creating...
  arn:                    "" => "<computed>"
  description:            "" => "EKS cluster security group."
  egress.#:               "" => "<computed>"
  ingress.#:              "" => "<computed>"
  name:                   "" => "<computed>"
  name_prefix:            "" => "poi-eks-cluster"
  owner_id:               "" => "<computed>"
  revoke_rules_on_delete: "" => "false"
  tags.%:                 "" => "2"
  tags.Environment:       "" => "poi-eks-env"
  tags.Name:              "" => "poi-eks-cluster-eks_cluster_sg"
  vpc_id:                 "" => "vpc-3842495d"
module.eks.aws_iam_role.cluster: Creation complete after 3s (ID: poi-eks-cluster20181112153249715300000001)
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy: Creating...
  policy_arn: "" => "arn:aws:iam::aws:policy/AmazonEKSServicePolicy"
  role:       "" => "poi-eks-cluster20181112153249715300000001"
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy: Creating...
  policy_arn: "" => "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
  role:       "" => "poi-eks-cluster20181112153249715300000001"
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy: Creation complete after 5s (ID: poi-eks-cluster20181112153249715300000001-20181112153254588500000003
)
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy: Creation complete after 5s (ID: poi-eks-cluster20181112153249715300000001-20181112153254606700000004
)
module.eks.aws_security_group.cluster: Creation complete after 9s (ID: sg-06a3ff8cc8240985f)
module.eks.aws_security_group_rule.cluster_egress_internet: Creating...
  cidr_blocks.#:            "" => "1"
  cidr_blocks.0:            "" => "0.0.0.0/0"
  description:              "" => "Allow cluster egress access to the Internet."
  from_port:                "" => "0"
  protocol:                 "" => "-1"
  security_group_id:        "" => "sg-06a3ff8cc8240985f"
  self:                     "" => "false"
  source_security_group_id: "" => "<computed>"
  to_port:                  "" => "0"
  type:                     "" => "egress"
module.eks.aws_eks_cluster.this: Creating...
  arn:                                        "" => "<computed>"
  certificate_authority.#:                    "" => "<computed>"
  created_at:                                 "" => "<computed>"
  endpoint:                                   "" => "<computed>"
  name:                                       "" => "poi-eks-cluster"
  platform_version:                           "" => "<computed>"
  role_arn:                                   "" => "arn:aws:iam::077978206904:role/poi-eks-cluster20181112153249715300000001"
  version:                                    "" => "1.10"
  vpc_config.#:                               "" => "1"
  vpc_config.0.security_group_ids.#:          "" => "1"
  vpc_config.0.security_group_ids.1658311772: "" => "sg-06a3ff8cc8240985f"
  vpc_config.0.subnet_ids.#:                  "" => "4"
  vpc_config.0.subnet_ids.360204655:          "" => "subnet-8813e1ec"
  vpc_config.0.subnet_ids.4209864939:         "" => "subnet-a3685afa"
  vpc_config.0.subnet_ids.4225826129:         "" => "subnet-a850bce0"
  vpc_config.0.subnet_ids.459373779:          "" => "subnet-c11f05b6"
  vpc_config.0.vpc_id:                        "" => "<computed>"
module.eks.aws_security_group_rule.cluster_egress_internet: Creation complete after 4s (ID: sgrule-3807598992)
module.eks.aws_eks_cluster.this: Still creating... (10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (1m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (2m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (3m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (4m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (5m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (6m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (7m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m30s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m40s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (8m50s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (9m0s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (9m10s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (9m20s elapsed)
module.eks.aws_eks_cluster.this: Still creating... (9m30s elapsed)
module.eks.aws_eks_cluster.this: Creation complete after 9m39s (ID: poi-eks-cluster)
module.eks.aws_iam_role.workers: Creating...
  arn:                   "" => "<computed>"
  assume_role_policy:    "" => "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"EKSWorkerAssumeRole\",\n      \"Effect\": \"Allow\",\n      \"A
ction\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"ec2.amazonaws.com\"\n      }\n    }\n  ]\n}"
  create_date:           "" => "<computed>"
  force_detach_policies: "" => "false"
  max_session_duration:  "" => "3600"
  name:                  "" => "<computed>"
  name_prefix:           "" => "poi-eks-cluster"
  path:                  "" => "/"
  unique_id:             "" => "<computed>"
module.eks.aws_security_group.workers: Creating...
  arn:                                        "" => "<computed>"
  description:                                "" => "Security group for all nodes in the cluster."
  egress.#:                                   "" => "<computed>"
  ingress.#:                                  "" => "<computed>"
  name:                                       "" => "<computed>"
  name_prefix:                                "" => "poi-eks-cluster"
  owner_id:                                   "" => "<computed>"
  revoke_rules_on_delete:                     "" => "false"
  tags.%:                                     "" => "3"
  tags.Environment:                           "" => "poi-eks-env"
  tags.Name:                                  "" => "poi-eks-cluster-eks_worker_sg"
  tags.kubernetes.io/cluster/poi-eks-cluster: "" => "owned"
  vpc_id:                                     "" => "vpc-3842495d"
module.eks.data.template_file.kubeconfig: Refreshing state...
module.eks.data.aws_iam_policy_document.worker_autoscaling: Refreshing state...
module.eks.aws_iam_policy.worker_autoscaling: Creating...
  arn:         "" => "<computed>"
  description: "" => "EKS worker node autoscaling policy for cluster poi-eks-cluster"
  name:        "" => "<computed>"
  name_prefix: "" => "eks-worker-autoscaling-poi-eks-cluster"
  path:        "" => "/"
  policy:      "" => "{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"eksWorkerAutoscalingAll\",\n      \"Effect\": \"Allow\",\n      \"Action\
": [\n        \"autoscaling:GetAsgForInstance\",\n        \"autoscaling:DescribeTags\",\n        \"autoscaling:DescribeLaunchConfigurations\",\n        \"autoscaling:Describe
AutoScalingInstances\",\n        \"autoscaling:DescribeAutoScalingGroups\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Sid\": \"eksWorkerAutoscalingOwn\",\n
     \"Effect\": \"Allow\",\n      \"Action\": [\n        \"autoscaling:UpdateAutoScalingGroup\",\n        \"autoscaling:TerminateInstanceInAutoScalingGroup\",\n        \"aut
oscaling:SetDesiredCapacity\"\n      ],\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"autoscaling:ResourceTag/k8s.io/cluster-a
utoscaler/enabled\": \"true\",\n          \"autoscaling:ResourceTag/kubernetes.io/cluster/poi-eks-cluster\": \"owned\"\n        }\n      }\n    }\n  ]\n}"
module.eks.local_file.kubeconfig: Creating...
  content:  "" => "apiVersion: v1\npreferences: {}\nkind: Config\n\nclusters:\n- cluster:\n    server: https://7EBF9FE21A4BF972A663ED343133C732.yl4.eu-west-1.eks.amazonaws.co
m\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjR
YRFRFNE1URXhNakUxTXprMU1Gb1hEVEk0TVRFd09URTFNemsxTUZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTGk3CmdPcDZyQ2ZEUmwvN
XdXdEcxQWYyRHdEcmhlc1Vha29aMDdNc3B0VHdBZitUTXFhdTNDQUhkQjJSVVM2ZnRIUzQKTEtVbUpOaVBQYnRlZ1Z5Nkc3K0k2WkxJSGo1MEU1aS96MTY1c1dJYnhScTBMeDZqWnN1a0lyOXdiTkNjNzdYMQpCYzZWUGxaa0JIMU9
BOGd0UU1YTnZMVU9DQjFOcjExb1pLWS9XNnJxM0VzY2NGSC9GV1hKSDJ4N2t6Z2g1RkMvCldpTDBzc21vUzU5cGpHamY1Wjh6M0hkNjd2Q0V5MFE5WnVDU3pONWxQeWVhRFdZeGQ4S1ZKcGlqc2Z6RWRhNjEKNWdDSUluQUY4a1Jyd
WdMUk9NTWg1T2h6enpublE4c0lId01ENnFlOFZzdlNKZ0VzVFdJMUJXZE5qSDQvTElCVApJSEdkNTM0VEFuTWcvWTZJci9VQ0F3RUFBYU1qTUNFd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0R
RWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFLaUdwbEgxdlNrZTR2WDlSVE8yNDlsaHplZkgKaWlYcWxtRmZ1WUIxZ2FhRVdOQW90dnJUdWdNMmhRT3pxaXN3Z0IrUXA5RHc2a2lOdklVYXJ5MmczK2hmaWkzQgpDMHpsSDUzaW5VTXlrR
FhJZHFjTE1lcmg2eGwwT01YSWVjVEg4VFBqTFVDK2Fobm1mOEZnSEdHZWlqUHdGczhOCkZoYWlVdWJlYTZjaHRRTExGeTd1aUhNaGVXTmJQRkFoN2NHZnJvVGkyekJtL3NRTFBGaE5OVXIxeVFzbUxXSkcKbE1XRk5MdXY0RVU2M3p
wSGxBOVRLaWNNU3lNQUtWZURNanVtcWRQenhlaHhFL2FsNDl1S1VENXdlcjEwRnk3YQpHbDJQNUoyQUE1azJMeVVIVCtnZnVPaTB2WWQreHgrWkxZNXpJNWFjNnJBT0xGMVF0MHo3N09uTkVqND0KLS0tLS1FTkQgQ0VSVElGSUNBV
EUtLS0tLQo=\n  name: eks_poi-eks-cluster\n\ncontexts:\n- context:\n    cluster: eks_poi-eks-cluster\n    user: eks_poi-eks-cluster\n  name: eks_poi-eks-cluster\n\ncurrent-con
text: eks_poi-eks-cluster\n\nusers:\n- name: eks_poi-eks-cluster\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1alpha1\n      command: aws-iam-authenti
cator\n      args:\n        - \"token\"\n        - \"-i\"\n        - \"poi-eks-cluster\"\n\n\n"
  filename: "" => "./kubeconfig_poi-eks-cluster"
module.eks.local_file.kubeconfig: Creation complete after 0s (ID: 4d834e32651897d0f015cdd5618437235b994678)
module.eks.aws_iam_role.workers: Creation complete after 3s (ID: poi-eks-cluster20181112154237674200000005)
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy: Creating...
  policy_arn: "" => "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
  role:       "" => "poi-eks-cluster20181112154237674200000005"
module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly: Creating...
  policy_arn: "" => "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
  role:       "" => "poi-eks-cluster20181112154237674200000005"
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy: Creating...
  policy_arn: "" => "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
  role:       "" => "poi-eks-cluster20181112154237674200000005"
module.eks.aws_iam_instance_profile.workers[1]: Creating...
  arn:         "" => "<computed>"
  create_date: "" => "<computed>"
  name:        "" => "<computed>"
  name_prefix: "" => "poi-eks-cluster"
  path:        "" => "/"
  role:        "" => "poi-eks-cluster20181112154237674200000005"
  roles.#:     "" => "<computed>"
  unique_id:   "" => "<computed>"
module.eks.aws_iam_instance_profile.workers[0]: Creating...
  arn:         "" => "<computed>"
  create_date: "" => "<computed>"
  name:        "" => "<computed>"
  name_prefix: "" => "poi-eks-cluster"
  path:        "" => "/"
  role:        "" => "poi-eks-cluster20181112154237674200000005"
  roles.#:     "" => "<computed>"
  unique_id:   "" => "<computed>"
module.eks.data.template_file.userdata[0]: Refreshing state...
module.eks.data.template_file.userdata[1]: Refreshing state...
module.eks.aws_iam_policy.worker_autoscaling: Creation complete after 5s (ID: arn:aws:iam::077978206904:policy/eks-wo...-eks-cluster20181112154237695200000007)
module.eks.aws_iam_role_policy_attachment.workers_autoscaling: Creating...
  policy_arn: "" => "arn:aws:iam::077978206904:policy/eks-worker-autoscaling-poi-eks-cluster20181112154237695200000007"
  role:       "" => "poi-eks-cluster20181112154237674200000005"
module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly: Creation complete after 5s (ID: poi-eks-cluster20181112154237674200000005-20181112154242
95110000000a)
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy: Creation complete after 5s (ID: poi-eks-cluster20181112154237674200000005-20181112154242975700000
00b)
module.eks.aws_iam_instance_profile.workers[0]: Creation complete after 5s (ID: poi-eks-cluster20181112154241405300000009)
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy: Creation complete after 5s (ID: poi-eks-cluster20181112154237674200000005-2018111215424297870000000c)
module.eks.aws_iam_instance_profile.workers[1]: Creation complete after 5s (ID: poi-eks-cluster20181112154241405300000008)
module.eks.data.template_file.worker_role_arns[1]: Refreshing state...
module.eks.data.template_file.worker_role_arns[0]: Refreshing state...
module.eks.data.template_file.config_map_aws_auth: Refreshing state...
module.eks.local_file.config_map_aws_auth: Creating...
  content:  "" => "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: aws-auth\n  namespace: kube-system\ndata:\n  mapRoles: |\n    - rolearn: arn:aws:iam::077978206904:role
/poi-eks-cluster20181112154237674200000005\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - system:bootstrappers\n        - system:nodes\n\n\n  ma
pUsers: |\n\n  mapAccounts: |\n\n"
  filename: "" => "./config-map-aws-auth_poi-eks-cluster.yaml"
module.eks.null_resource.update_config_map_aws_auth: Creating...
  triggers.%:                   "" => "1"
  triggers.config_map_rendered: "" => "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: aws-auth\n  namespace: kube-system\ndata:\n  mapRoles: |\n    - rolearn: arn:aws:ia
m::077978206904:role/poi-eks-cluster20181112154237674200000005\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - system:bootstrappers\n        - sy
stem:nodes\n\n\n  mapUsers: |\n\n  mapAccounts: |\n\n"
module.eks.null_resource.update_config_map_aws_auth: Provisioning with 'local-exec'...
module.eks.local_file.config_map_aws_auth: Creation complete after 0s (ID: 9b7f2700777d814219cf961440c12defa1b248f8)
module.eks.null_resource.update_config_map_aws_auth (local-exec): Executing: ["cmd" "/C" "kubectl apply -f ./config-map-aws-auth_poi-eks-cluster.yaml --kubeconfig ./kubeconfi
g_poi-eks-cluster"]
module.eks.aws_security_group.workers: Creation complete after 9s (ID: sg-0e2a774557e53522a)
module.eks.aws_security_group_rule.workers_ingress_cluster_https: Creating...
  description:              "" => "Allow pods running extension API servers on port 443 to receive communication from cluster control plane."
  from_port:                "" => "443"
  protocol:                 "" => "tcp"
  security_group_id:        "" => "sg-0e2a774557e53522a"
  self:                     "" => "false"
  source_security_group_id: "" => "sg-06a3ff8cc8240985f"
  to_port:                  "" => "443"
  type:                     "" => "ingress"
module.eks.aws_security_group_rule.workers_egress_internet: Creating...
  cidr_blocks.#:            "" => "1"
  cidr_blocks.0:            "" => "0.0.0.0/0"
  description:              "" => "Allow nodes all egress to the Internet."
  from_port:                "" => "0"
  protocol:                 "" => "-1"
  security_group_id:        "" => "sg-0e2a774557e53522a"
  self:                     "" => "false"
  source_security_group_id: "" => "<computed>"
  to_port:                  "" => "0"
  type:                     "" => "egress"
module.eks.aws_security_group_rule.workers_ingress_self: Creating...
  description:              "" => "Allow node to communicate with each other."
  from_port:                "" => "0"
  protocol:                 "" => "-1"
  security_group_id:        "" => "sg-0e2a774557e53522a"
  self:                     "" => "false"
  source_security_group_id: "" => "sg-0e2a774557e53522a"
  to_port:                  "" => "65535"
  type:                     "" => "ingress"
module.eks.aws_security_group_rule.workers_ingress_cluster: Creating...
  description:              "" => "Allow workers Kubelets and pods to receive communication from the cluster control plane."
  from_port:                "" => "1025"
  protocol:                 "" => "tcp"
  security_group_id:        "" => "sg-0e2a774557e53522a"
  self:                     "" => "false"
  source_security_group_id: "" => "sg-06a3ff8cc8240985f"
  to_port:                  "" => "65535"
  type:                     "" => "ingress"
module.eks.aws_security_group_rule.cluster_https_worker_ingress: Creating...
  description:              "" => "Allow pods to communicate with the EKS cluster API."
  from_port:                "" => "443"
  protocol:                 "" => "tcp"
  security_group_id:        "" => "sg-06a3ff8cc8240985f"
  self:                     "" => "false"
  source_security_group_id: "" => "sg-0e2a774557e53522a"
  to_port:                  "" => "443"
  type:                     "" => "ingress"
module.eks.aws_launch_configuration.workers[0]: Creating...
  associate_public_ip_address:               "" => "false"
  ebs_block_device.#:                        "" => "<computed>"
  ebs_optimized:                             "" => "false"
  enable_monitoring:                         "" => "true"
  iam_instance_profile:                      "" => "poi-eks-cluster20181112154241405300000009"
  image_id:                                  "" => "ami-00c3b2d35bddd4f5c"
  instance_type:                             "" => "t2.medium"
  key_name:                                  "" => "<computed>"
  name:                                      "" => "<computed>"
  name_prefix:                               "" => "poi-eks-cluster-0"
  root_block_device.#:                       "" => "1"
  root_block_device.0.delete_on_termination: "" => "true"
  root_block_device.0.iops:                  "" => "0"
  root_block_device.0.volume_size:           "" => "100"
  root_block_device.0.volume_type:           "" => "gp2"
  security_groups.#:                         "" => "1"
  security_groups.1424228325:                "" => "sg-0e2a774557e53522a"
  user_data_base64:                          "" => "IyEvYmluL2Jhc2ggLXhlCgojIEFsbG93IHVzZXIgc3VwcGxpZWQgcHJlIHVzZXJkYXRhIGNvZGUKCgojIEJvb3RzdHJhcCBhbmQgam9pbiB0aGUgY2x1c3Rlcg
ovZXRjL2Vrcy9ib290c3RyYXAuc2ggLS1iNjQtY2x1c3Rlci1jYSAnTFMwdExTMUNSVWRKVGlCRFJWSlVTVVpKUTBGVVJTMHRMUzB0Q2sxSlNVTjVSRU5EUVdKRFowRjNTVUpCWjBsQ1FVUkJUa0puYTNGb2EybEhPWGN3UWtGUmMw
WkJSRUZXVFZKTmQwVlJXVVJXVVZGRVJYZHdjbVJYU213S1kyMDFiR1JIVm5wTlFqUllSRlJGTkUxVVJYaE5ha1V4VFhwck1VMUdiMWhFVkVrMFRWUkZkMDlVUlRGTmVtc3hUVVp2ZDBaVVJWUk5Ra1ZIUVRGVlJRcEJlRTFMWVROV2
FWcFlTblZhV0ZKc1kzcERRMEZUU1hkRVVWbEtTMjlhU1doMlkwNUJVVVZDUWxGQlJHZG5SVkJCUkVORFFWRnZRMmRuUlVKQlRHazNDbWRQY0RaeVEyWkVVbXd2TlhkWGRFY3hRV1l5UkhkRWNtaGxjMVZoYTI5YU1EZE5jM0IwVkhk
QlppdFVUWEZoZFRORFFVaGtRakpTVlZNMlpuUklVelFLVEV0VmJVcE9hVkJRWW5SbFoxWjVOa2MzSzBrMldreEpTR28xTUVVMWFTOTZNVFkxYzFkSlluaFNjVEJNZURacVduTjFhMGx5T1hkaVRrTmpOemRZTVFwQ1l6WldVR3hhYT
BKSU1VOUJPR2QwVVUxWVRuWk1WVTlEUWpGT2NqRXhiMXBMV1M5WE5uSnhNMFZ6WTJOR1NDOUdWMWhLU0RKNE4ydDZaMmcxUmtNdkNsZHBUREJ6YzIxdlV6VTVjR3BIYW1ZMVdqaDZNMGhrTmpkMlEwVjVNRkU1V25WRFUzcE9OV3hR
ZVdWaFJGZFplR1E0UzFaS2NHbHFjMlo2UldSaE5qRUtOV2REU1VsdVFVWTRhMUp5ZFdkTVVrOU5UV2cxVDJoNmVucHVibEU0YzBsSWQwMUVObkZsT0ZaemRsTktaMFZ6VkZkSk1VSlhaRTVxU0RRdlRFbENWQXBKU0Vka05UTTBWRU
Z1VFdjdldUWkpjaTlWUTBGM1JVRkJZVTFxVFVORmQwUm5XVVJXVWpCUVFWRklMMEpCVVVSQlowdHJUVUU0UjBFeFZXUkZkMFZDQ2k5M1VVWk5RVTFDUVdZNGQwUlJXVXBMYjFwSmFIWmpUa0ZSUlV4Q1VVRkVaMmRGUWtGTGFVZHdi
RWd4ZGxOclpUUjJXRGxTVkU4eU5EbHNhSHBsWmtnS2FXbFljV3h0Um1aMVdVSXhaMkZoUlZkT1FXOTBkbkpVZFdkTk1taFJUM3B4YVhOM1owSXJVWEE1UkhjMmEybE9ka2xWWVhKNU1tY3pLMmhtYVdrelFncERNSHBzU0RVemFXNV
ZUWGxyUkZoSlpIRmpURTFsY21nMmVHd3dUMDFZU1dWalZFZzRWRkJxVEZWREsyRm9ibTFtT0VablNFZEhaV2xxVUhkR2N6aE9Da1pvWVdsVmRXSmxZVFpqYUhSUlRFeEdlVGQxYVVoTmFHVlhUbUpRUmtGb04yTkhabkp2VkdreWVr
SnRMM05SVEZCR2FFNU9WWEl4ZVZGemJVeFhTa2NLYkUxWFJrNU1kWFkwUlZVMk0zcHdTR3hCT1ZSTGFXTk5VM2xOUVV0V1pVUk5hblZ0Y1dSUWVuaGxhSGhGTDJGc05EbDFTMVZFTlhkbGNqRXdSbmszWVFwSGJESlFOVW95UVVFMW
F6Sk1lVlZJVkN0blpuVlBhVEIyV1dRcmVIZ3JXa3haTlhwSk5XRmpObkpCVDB4R01WRjBNSG8zTjA5dVRrVnFORDBLTFMwdExTMUZUa1FnUTBWU1ZFbEdTVU5CVkVVdExTMHRMUW89JyAtLWFwaXNlcnZlci1lbmRwb2ludCAnaHR0
cHM6Ly83RUJGOUZFMjFBNEJGOTcyQTY2M0VEMzQzMTMzQzczMi55bDQuZXUtd2VzdC0xLmVrcy5hbWF6b25hd3MuY29tJyAtLWt1YmVsZXQtZXh0cmEtYXJncyAnJyAncG9pLWVrcy1jbHVzdGVyJwoKIyBBbGxvdyB1c2VyIHN1cH
BsaWVkIHVzZXJkYXRhIGNvZGUKCg=="
module.eks.aws_launch_configuration.workers[1]: Creating...
  associate_public_ip_address:               "" => "false"
  ebs_block_device.#:                        "" => "<computed>"
  ebs_optimized:                             "" => "false"
  enable_monitoring:                         "" => "true"
  iam_instance_profile:                      "" => "poi-eks-cluster20181112154241405300000008"
  image_id:                                  "" => "ami-00c3b2d35bddd4f5c"
  instance_type:                             "" => "t2.large"
  key_name:                                  "" => "<computed>"
  name:                                      "" => "<computed>"
  name_prefix:                               "" => "poi-eks-cluster-1"
  root_block_device.#:                       "" => "1"
  root_block_device.0.delete_on_termination: "" => "true"
  root_block_device.0.iops:                  "" => "0"
  root_block_device.0.volume_size:           "" => "100"
  root_block_device.0.volume_type:           "" => "gp2"
  security_groups.#:                         "" => "1"
  security_groups.1424228325:                "" => "sg-0e2a774557e53522a"
  user_data_base64:                          "" => "IyEvYmluL2Jhc2ggLXhlCgojIEFsbG93IHVzZXIgc3VwcGxpZWQgcHJlIHVzZXJkYXRhIGNvZGUKCgojIEJvb3RzdHJhcCBhbmQgam9pbiB0aGUgY2x1c3Rlcg
ovZXRjL2Vrcy9ib290c3RyYXAuc2ggLS1iNjQtY2x1c3Rlci1jYSAnTFMwdExTMUNSVWRKVGlCRFJWSlVTVVpKUTBGVVJTMHRMUzB0Q2sxSlNVTjVSRU5EUVdKRFowRjNTVUpCWjBsQ1FVUkJUa0puYTNGb2EybEhPWGN3UWtGUmMw
WkJSRUZXVFZKTmQwVlJXVVJXVVZGRVJYZHdjbVJYU213S1kyMDFiR1JIVm5wTlFqUllSRlJGTkUxVVJYaE5ha1V4VFhwck1VMUdiMWhFVkVrMFRWUkZkMDlVUlRGTmVtc3hUVVp2ZDBaVVJWUk5Ra1ZIUVRGVlJRcEJlRTFMWVROV2
FWcFlTblZhV0ZKc1kzcERRMEZUU1hkRVVWbEtTMjlhU1doMlkwNUJVVVZDUWxGQlJHZG5SVkJCUkVORFFWRnZRMmRuUlVKQlRHazNDbWRQY0RaeVEyWkVVbXd2TlhkWGRFY3hRV1l5UkhkRWNtaGxjMVZoYTI5YU1EZE5jM0IwVkhk
QlppdFVUWEZoZFRORFFVaGtRakpTVlZNMlpuUklVelFLVEV0VmJVcE9hVkJRWW5SbFoxWjVOa2MzSzBrMldreEpTR28xTUVVMWFTOTZNVFkxYzFkSlluaFNjVEJNZURacVduTjFhMGx5T1hkaVRrTmpOemRZTVFwQ1l6WldVR3hhYT
BKSU1VOUJPR2QwVVUxWVRuWk1WVTlEUWpGT2NqRXhiMXBMV1M5WE5uSnhNMFZ6WTJOR1NDOUdWMWhLU0RKNE4ydDZaMmcxUmtNdkNsZHBUREJ6YzIxdlV6VTVjR3BIYW1ZMVdqaDZNMGhrTmpkMlEwVjVNRkU1V25WRFUzcE9OV3hR
ZVdWaFJGZFplR1E0UzFaS2NHbHFjMlo2UldSaE5qRUtOV2REU1VsdVFVWTRhMUp5ZFdkTVVrOU5UV2cxVDJoNmVucHVibEU0YzBsSWQwMUVObkZsT0ZaemRsTktaMFZ6VkZkSk1VSlhaRTVxU0RRdlRFbENWQXBKU0Vka05UTTBWRU
Z1VFdjdldUWkpjaTlWUTBGM1JVRkJZVTFxVFVORmQwUm5XVVJXVWpCUVFWRklMMEpCVVVSQlowdHJUVUU0UjBFeFZXUkZkMFZDQ2k5M1VVWk5RVTFDUVdZNGQwUlJXVXBMYjFwSmFIWmpUa0ZSUlV4Q1VVRkVaMmRGUWtGTGFVZHdi
RWd4ZGxOclpUUjJXRGxTVkU4eU5EbHNhSHBsWmtnS2FXbFljV3h0Um1aMVdVSXhaMkZoUlZkT1FXOTBkbkpVZFdkTk1taFJUM3B4YVhOM1owSXJVWEE1UkhjMmEybE9ka2xWWVhKNU1tY3pLMmhtYVdrelFncERNSHBzU0RVemFXNV
ZUWGxyUkZoSlpIRmpURTFsY21nMmVHd3dUMDFZU1dWalZFZzRWRkJxVEZWREsyRm9ibTFtT0VablNFZEhaV2xxVUhkR2N6aE9Da1pvWVdsVmRXSmxZVFpqYUhSUlRFeEdlVGQxYVVoTmFHVlhUbUpRUmtGb04yTkhabkp2VkdreWVr
SnRMM05SVEZCR2FFNU9WWEl4ZVZGemJVeFhTa2NLYkUxWFJrNU1kWFkwUlZVMk0zcHdTR3hCT1ZSTGFXTk5VM2xOUVV0V1pVUk5hblZ0Y1dSUWVuaGxhSGhGTDJGc05EbDFTMVZFTlhkbGNqRXdSbmszWVFwSGJESlFOVW95UVVFMW
F6Sk1lVlZJVkN0blpuVlBhVEIyV1dRcmVIZ3JXa3haTlhwSk5XRmpObkpCVDB4R01WRjBNSG8zTjA5dVRrVnFORDBLTFMwdExTMUZUa1FnUTBWU1ZFbEdTVU5CVkVVdExTMHRMUW89JyAtLWFwaXNlcnZlci1lbmRwb2ludCAnaHR0
cHM6Ly83RUJGOUZFMjFBNEJGOTcyQTY2M0VEMzQzMTMzQzczMi55bDQuZXUtd2VzdC0xLmVrcy5hbWF6b25hd3MuY29tJyAtLWt1YmVsZXQtZXh0cmEtYXJncyAnJyAncG9pLWVrcy1jbHVzdGVyJwoKIyBBbGxvdyB1c2VyIHN1cH
BsaWVkIHVzZXJkYXRhIGNvZGUKCg=="
module.eks.aws_iam_role_policy_attachment.workers_autoscaling: Creation complete after 5s (ID: poi-eks-cluster20181112154237674200000005-2018111215424478780000000d)
module.eks.aws_security_group_rule.workers_ingress_cluster_https: Creation complete after 4s (ID: sgrule-3844219644)
module.eks.aws_security_group_rule.cluster_https_worker_ingress: Creation complete after 4s (ID: sgrule-1352200867)
module.eks.aws_security_group_rule.workers_egress_internet: Creation complete after 8s (ID: sgrule-2956176906)
module.eks.null_resource.update_config_map_aws_auth: Still creating... (10s elapsed)
module.eks.aws_launch_configuration.workers[0]: Creation complete after 9s (ID: poi-eks-cluster-02018111215425005410000000e)
module.eks.aws_launch_configuration.workers[1]: Creation complete after 10s (ID: poi-eks-cluster-12018111215425006420000000f)
module.eks.aws_autoscaling_group.workers[0]: Creating...
  arn:                            "" => "<computed>"
  default_cooldown:               "" => "<computed>"
  desired_capacity:               "" => "3"
  force_delete:                   "" => "false"
  health_check_grace_period:      "" => "300"
  health_check_type:              "" => "<computed>"
  launch_configuration:           "" => "poi-eks-cluster-02018111215425005410000000e"
  load_balancers.#:               "" => "<computed>"
  max_size:                       "" => "4"
  metrics_granularity:            "" => "1Minute"
  min_size:                       "" => "1"
  name:                           "" => "<computed>"
  name_prefix:                    "" => "poi-eks-cluster-0"
  protect_from_scale_in:          "" => "false"
  service_linked_role_arn:        "" => "<computed>"
  tags.#:                         "" => "4"
  tags.0.%:                       "" => "3"
  tags.0.key:                     "" => "Name"
  tags.0.propagate_at_launch:     "" => "1"
  tags.0.value:                   "" => "poi-eks-cluster-0-eks_asg"
  tags.1.%:                       "" => "3"
  tags.1.key:                     "" => "kubernetes.io/cluster/poi-eks-cluster"
  tags.1.propagate_at_launch:     "" => "1"
  tags.1.value:                   "" => "owned"
  tags.2.%:                       "" => "3"
  tags.2.key:                     "" => "k8s.io/cluster-autoscaler/disabled"
  tags.2.propagate_at_launch:     "" => "0"
  tags.2.value:                   "" => "true"
  tags.3.%:                       "" => "3"
  tags.3.key:                     "" => "Environment"
  tags.3.propagate_at_launch:     "" => "1"
  tags.3.value:                   "" => "poi-eks-env"
  target_group_arns.#:            "" => "<computed>"
  vpc_zone_identifier.#:          "" => "4"
  vpc_zone_identifier.1004225602: "" => "subnet-a850bce0"
  vpc_zone_identifier.1874057288: "" => "subnet-c11f05b6"
  vpc_zone_identifier.2903397952: "" => "subnet-8813e1ec"
  vpc_zone_identifier.3978819587: "" => "subnet-a3685afa"
  wait_for_capacity_timeout:      "" => "10m"
module.eks.aws_autoscaling_group.workers[1]: Creating...
  arn:                            "" => "<computed>"
  default_cooldown:               "" => "<computed>"
  desired_capacity:               "" => "2"
  force_delete:                   "" => "false"
  health_check_grace_period:      "" => "300"
  health_check_type:              "" => "<computed>"
  launch_configuration:           "" => "poi-eks-cluster-12018111215425006420000000f"
  load_balancers.#:               "" => "<computed>"
  max_size:                       "" => "3"
  metrics_granularity:            "" => "1Minute"
  min_size:                       "" => "1"
  name:                           "" => "<computed>"
  name_prefix:                    "" => "poi-eks-cluster-1"
  protect_from_scale_in:          "" => "false"
  service_linked_role_arn:        "" => "<computed>"
  tags.#:                         "" => "4"
  tags.0.%:                       "" => "3"
  tags.0.key:                     "" => "Name"
  tags.0.propagate_at_launch:     "" => "1"
  tags.0.value:                   "" => "poi-eks-cluster-1-eks_asg"
  tags.1.%:                       "" => "3"
  tags.1.key:                     "" => "kubernetes.io/cluster/poi-eks-cluster"
  tags.1.propagate_at_launch:     "" => "1"
  tags.1.value:                   "" => "owned"
  tags.2.%:                       "" => "3"
  tags.2.key:                     "" => "k8s.io/cluster-autoscaler/disabled"
  tags.2.propagate_at_launch:     "" => "0"
  tags.2.value:                   "" => "true"
  tags.3.%:                       "" => "3"
  tags.3.key:                     "" => "Environment"
  tags.3.propagate_at_launch:     "" => "1"
  tags.3.value:                   "" => "poi-eks-env"
  target_group_arns.#:            "" => "<computed>"
  vpc_zone_identifier.#:          "" => "4"
  vpc_zone_identifier.1004225602: "" => "subnet-a850bce0"
  vpc_zone_identifier.1874057288: "" => "subnet-c11f05b6"
  vpc_zone_identifier.2903397952: "" => "subnet-8813e1ec"
  vpc_zone_identifier.3978819587: "" => "subnet-a3685afa"
  wait_for_capacity_timeout:      "" => "10m"
module.eks.aws_security_group_rule.workers_ingress_self: Still creating... (10s elapsed)
module.eks.aws_security_group_rule.workers_ingress_cluster: Still creating... (10s elapsed)
module.eks.aws_security_group_rule.workers_ingress_cluster: Creation complete after 12s (ID: sgrule-3065867568)
module.eks.aws_security_group_rule.workers_ingress_self: Creation complete after 16s (ID: sgrule-1115134885)
module.eks.null_resource.update_config_map_aws_auth: Still creating... (20s elapsed)
module.eks.null_resource.update_config_map_aws_auth (local-exec): configmap "aws-auth" created
module.eks.null_resource.update_config_map_aws_auth: Creation complete after 20s (ID: 1823205252380539845)
module.eks.aws_autoscaling_group.workers.0: Still creating... (10s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still creating... (10s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (20s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still creating... (20s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (30s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still creating... (30s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (40s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still creating... (40s elapsed)
module.eks.aws_autoscaling_group.workers[1]: Creation complete after 48s (ID: poi-eks-cluster-120181112154256533300000011)
module.eks.aws_autoscaling_group.workers.0: Still creating... (50s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (1m0s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (1m10s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (1m20s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (1m30s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (1m40s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (1m50s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (2m0s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (2m10s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (2m20s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (2m30s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (2m40s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still creating... (2m50s elapsed)
module.eks.aws_autoscaling_group.workers[0]: Creation complete after 2m53s (ID: poi-eks-cluster-020181112154256531300000010)

Apply complete! Resources: 28 added, 0 changed, 0 destroyed.
PS C:\DDrive\MyData\Yogesh\git_repo\DevOps\kubernetes\aws-eks> kubectl --kubeconfig .\kubeconfig_poi-eks-cluster get nodes
NAME                                           STATUS    ROLES     AGE       VERSION
ip-172-29-118-192.eu-west-1.compute.internal   Ready     <none>    3m        v1.10.3
ip-172-29-118-89.eu-west-1.compute.internal    Ready     <none>    4m        v1.10.3
ip-172-29-119-18.eu-west-1.compute.internal    Ready     <none>    4m        v1.10.3
ip-172-29-119-93.eu-west-1.compute.internal    Ready     <none>    4m        v1.10.3
ip-172-29-226-14.eu-west-1.compute.internal    Ready     <none>    4m        v1.10.3
PS C:\DDrive\MyData\Yogesh\git_repo\DevOps\kubernetes\aws-eks> terraform destroy
null_resource.tags_as_list_of_maps: Refreshing state... (ID: 1363439499390715014)
aws_security_group.cluster: Refreshing state... (ID: sg-06a3ff8cc8240985f)
data.aws_caller_identity.current: Refreshing state...
data.aws_iam_policy_document.workers_assume_role_policy: Refreshing state...
data.aws_iam_policy_document.cluster_assume_role_policy: Refreshing state...
data.aws_region.current: Refreshing state...
data.aws_ami.eks_worker: Refreshing state...
aws_iam_role.cluster: Refreshing state... (ID: poi-eks-cluster20181112153249715300000001)
aws_security_group_rule.cluster_egress_internet: Refreshing state... (ID: sgrule-3807598992)
aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy: Refreshing state... (ID: poi-eks-cluster20181112153249715300000001-20181112153254606700000004)
aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy: Refreshing state... (ID: poi-eks-cluster20181112153249715300000001-20181112153254588500000003)
aws_eks_cluster.this: Refreshing state... (ID: poi-eks-cluster)
aws_security_group.workers: Refreshing state... (ID: sg-0e2a774557e53522a)
aws_iam_role.workers: Refreshing state... (ID: poi-eks-cluster20181112154237674200000005)
data.aws_iam_policy_document.worker_autoscaling: Refreshing state...
data.template_file.kubeconfig: Refreshing state...
aws_iam_policy.worker_autoscaling: Refreshing state... (ID: arn:aws:iam::077978206904:policy/eks-wo...-eks-cluster20181112154237695200000007)
local_file.kubeconfig: Refreshing state... (ID: 4d834e32651897d0f015cdd5618437235b994678)
aws_security_group_rule.workers_ingress_self: Refreshing state... (ID: sgrule-1115134885)
aws_security_group_rule.workers_ingress_cluster_https: Refreshing state... (ID: sgrule-3844219644)
aws_security_group_rule.workers_ingress_cluster: Refreshing state... (ID: sgrule-3065867568)
aws_security_group_rule.workers_egress_internet: Refreshing state... (ID: sgrule-2956176906)
aws_security_group_rule.cluster_https_worker_ingress: Refreshing state... (ID: sgrule-1352200867)
aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy: Refreshing state... (ID: poi-eks-cluster20181112154237674200000005-2018111215424297870000000c)
aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy: Refreshing state... (ID: poi-eks-cluster20181112154237674200000005-2018111215424297570000000b)
aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly: Refreshing state... (ID: poi-eks-cluster20181112154237674200000005-2018111215424295110000000a)
data.template_file.userdata[0]: Refreshing state...
data.template_file.userdata[1]: Refreshing state...
aws_iam_instance_profile.workers[1]: Refreshing state... (ID: poi-eks-cluster20181112154241405300000008)
aws_iam_instance_profile.workers[0]: Refreshing state... (ID: poi-eks-cluster20181112154241405300000009)
aws_iam_role_policy_attachment.workers_autoscaling: Refreshing state... (ID: poi-eks-cluster20181112154237674200000005-2018111215424478780000000d)
aws_launch_configuration.workers[1]: Refreshing state... (ID: poi-eks-cluster-12018111215425006420000000f)
aws_launch_configuration.workers[0]: Refreshing state... (ID: poi-eks-cluster-02018111215425005410000000e)
data.template_file.worker_role_arns[0]: Refreshing state...
data.template_file.worker_role_arns[1]: Refreshing state...
data.template_file.config_map_aws_auth: Refreshing state...
local_file.config_map_aws_auth: Refreshing state... (ID: 9b7f2700777d814219cf961440c12defa1b248f8)
null_resource.update_config_map_aws_auth: Refreshing state... (ID: 1823205252380539845)
aws_autoscaling_group.workers[0]: Refreshing state... (ID: poi-eks-cluster-020181112154256531300000010)
aws_autoscaling_group.workers[1]: Refreshing state... (ID: poi-eks-cluster-120181112154256533300000011)

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  - module.eks.aws_autoscaling_group.workers[0]

  - module.eks.aws_autoscaling_group.workers[1]

  - module.eks.aws_eks_cluster.this

  - module.eks.aws_iam_instance_profile.workers[0]

  - module.eks.aws_iam_instance_profile.workers[1]

  - module.eks.aws_iam_policy.worker_autoscaling

  - module.eks.aws_iam_role.cluster

  - module.eks.aws_iam_role.workers

  - module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy

  - module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy

  - module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly

  - module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy

  - module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy

  - module.eks.aws_iam_role_policy_attachment.workers_autoscaling

  - module.eks.aws_launch_configuration.workers[0]

  - module.eks.aws_launch_configuration.workers[1]

  - module.eks.aws_security_group.cluster

  - module.eks.aws_security_group.workers

  - module.eks.aws_security_group_rule.cluster_egress_internet

  - module.eks.aws_security_group_rule.cluster_https_worker_ingress

  - module.eks.aws_security_group_rule.workers_egress_internet

  - module.eks.aws_security_group_rule.workers_ingress_cluster

  - module.eks.aws_security_group_rule.workers_ingress_cluster_https

  - module.eks.aws_security_group_rule.workers_ingress_self

  - module.eks.local_file.config_map_aws_auth

  - module.eks.local_file.kubeconfig

  - module.eks.null_resource.tags_as_list_of_maps

  - module.eks.null_resource.update_config_map_aws_auth


Plan: 0 to add, 0 to change, 28 to destroy.

Do you really want to destroy all resources?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

module.eks.null_resource.update_config_map_aws_auth: Destroying... (ID: 1823205252380539845)
module.eks.local_file.kubeconfig: Destroying... (ID: 4d834e32651897d0f015cdd5618437235b994678)
module.eks.local_file.config_map_aws_auth: Destroying... (ID: 9b7f2700777d814219cf961440c12defa1b248f8)
module.eks.null_resource.update_config_map_aws_auth: Destruction complete after 0s
module.eks.local_file.kubeconfig: Destruction complete after 0s
module.eks.local_file.config_map_aws_auth: Destruction complete after 0s
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy: Destroying... (ID: poi-eks-cluster20181112154237674200000005-2018111215424297870000000c)
module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly: Destroying... (ID: poi-eks-cluster20181112154237674200000005-2018111215424295110000000a)
module.eks.aws_iam_role_policy_attachment.workers_autoscaling: Destroying... (ID: poi-eks-cluster20181112154237674200000005-2018111215424478780000000d)
module.eks.aws_autoscaling_group.workers[0]: Destroying... (ID: poi-eks-cluster-020181112154256531300000010)
module.eks.aws_security_group_rule.workers_ingress_cluster: Destroying... (ID: sgrule-3065867568)
module.eks.aws_security_group_rule.cluster_egress_internet: Destroying... (ID: sgrule-3807598992)
module.eks.aws_security_group_rule.workers_egress_internet: Destroying... (ID: sgrule-2956176906)
module.eks.aws_security_group_rule.workers_ingress_cluster_https: Destroying... (ID: sgrule-3844219644)
module.eks.aws_security_group_rule.workers_ingress_self: Destroying... (ID: sgrule-1115134885)
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy: Destroying... (ID: poi-eks-cluster20181112154237674200000005-2018111215424297570000000b)
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy: Destruction complete after 2s
module.eks.aws_security_group_rule.cluster_https_worker_ingress: Destroying... (ID: sgrule-1352200867)
module.eks.aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly: Destruction complete after 2s
module.eks.aws_autoscaling_group.workers[1]: Destroying... (ID: poi-eks-cluster-120181112154256533300000011)
module.eks.aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy: Destruction complete after 2s
module.eks.aws_iam_role_policy_attachment.workers_autoscaling: Destruction complete after 2s
module.eks.aws_iam_policy.worker_autoscaling: Destroying... (ID: arn:aws:iam::077978206904:policy/eks-wo...-eks-cluster20181112154237695200000007)
module.eks.aws_security_group_rule.workers_ingress_cluster: Destruction complete after 2s
module.eks.aws_security_group_rule.cluster_egress_internet: Destruction complete after 2s
module.eks.aws_iam_policy.worker_autoscaling: Destruction complete after 3s
module.eks.aws_security_group_rule.workers_ingress_cluster_https: Destruction complete after 5s
module.eks.aws_security_group_rule.cluster_https_worker_ingress: Destruction complete after 3s
module.eks.aws_security_group_rule.workers_ingress_self: Destruction complete after 8s
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 10s elapsed)
module.eks.aws_security_group_rule.workers_egress_internet: Still destroying... (ID: sgrule-2956176906, 10s elapsed)
module.eks.aws_security_group_rule.workers_egress_internet: Destruction complete after 10s
module.eks.aws_autoscaling_group.workers.1: Still destroying... (ID: poi-eks-cluster-120181112154256533300000011, 10s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 20s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still destroying... (ID: poi-eks-cluster-120181112154256533300000011, 20s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 30s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still destroying... (ID: poi-eks-cluster-120181112154256533300000011, 30s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 40s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still destroying... (ID: poi-eks-cluster-120181112154256533300000011, 40s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 50s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still destroying... (ID: poi-eks-cluster-120181112154256533300000011, 50s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 1m0s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still destroying... (ID: poi-eks-cluster-120181112154256533300000011, 1m0s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 1m10s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still destroying... (ID: poi-eks-cluster-120181112154256533300000011, 1m10s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 1m20s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still destroying... (ID: poi-eks-cluster-120181112154256533300000011, 1m20s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 1m30s elapsed)
module.eks.aws_autoscaling_group.workers.1: Still destroying... (ID: poi-eks-cluster-120181112154256533300000011, 1m30s elapsed)
module.eks.aws_autoscaling_group.workers[1]: Destruction complete after 1m37s
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 1m40s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 1m50s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 2m0s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 2m10s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 2m20s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 2m30s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 2m40s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 2m50s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 3m0s elapsed)
module.eks.aws_autoscaling_group.workers.0: Still destroying... (ID: poi-eks-cluster-020181112154256531300000010, 3m10s elapsed)
module.eks.aws_autoscaling_group.workers[0]: Destruction complete after 3m17s
module.eks.null_resource.tags_as_list_of_maps: Destroying... (ID: 1363439499390715014)
module.eks.aws_launch_configuration.workers[0]: Destroying... (ID: poi-eks-cluster-02018111215425005410000000e)
module.eks.aws_launch_configuration.workers[1]: Destroying... (ID: poi-eks-cluster-12018111215425006420000000f)
module.eks.null_resource.tags_as_list_of_maps: Destruction complete after 0s
module.eks.aws_launch_configuration.workers[0]: Destruction complete after 1s
module.eks.aws_launch_configuration.workers[1]: Destruction complete after 1s
module.eks.aws_security_group.workers: Destroying... (ID: sg-0e2a774557e53522a)
module.eks.aws_iam_instance_profile.workers[1]: Destroying... (ID: poi-eks-cluster20181112154241405300000008)
module.eks.aws_iam_instance_profile.workers[0]: Destroying... (ID: poi-eks-cluster20181112154241405300000009)
module.eks.aws_security_group.workers: Destruction complete after 3s
module.eks.aws_iam_instance_profile.workers[0]: Destruction complete after 3s
module.eks.aws_iam_instance_profile.workers[1]: Destruction complete after 3s
module.eks.aws_iam_role.workers: Destroying... (ID: poi-eks-cluster20181112154237674200000005)
module.eks.aws_iam_role.workers: Destruction complete after 3s
module.eks.aws_eks_cluster.this: Destroying... (ID: poi-eks-cluster)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 10s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 20s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 30s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 40s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 50s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 1m0s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 1m10s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 1m20s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 1m30s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 1m40s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 1m50s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 2m0s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 2m10s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 2m20s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 2m30s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 2m40s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 2m50s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 3m0s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 3m10s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 3m20s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 3m30s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 3m40s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 3m50s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 4m0s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 4m10s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 4m20s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 4m30s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 4m40s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 4m50s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 5m0s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 5m10s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 5m20s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 5m30s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 5m40s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 5m50s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 6m0s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 6m10s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 6m20s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 6m30s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 6m40s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 6m50s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 7m0s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 7m10s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 7m20s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 7m30s elapsed)
module.eks.aws_eks_cluster.this: Still destroying... (ID: poi-eks-cluster, 7m40s elapsed)
module.eks.aws_eks_cluster.this: Destruction complete after 7m48s
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy: Destroying... (ID: poi-eks-cluster20181112153249715300000001-20181112153254606700000004)
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy: Destroying... (ID: poi-eks-cluster20181112153249715300000001-20181112153254588500000003)
module.eks.aws_security_group.cluster: Destroying... (ID: sg-06a3ff8cc8240985f)
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy: Destruction complete after 1s
module.eks.aws_iam_role_policy_attachment.cluster_AmazonEKSServicePolicy: Destruction complete after 1s
module.eks.aws_iam_role.cluster: Destroying... (ID: poi-eks-cluster20181112153249715300000001)
module.eks.aws_security_group.cluster: Destruction complete after 3s
module.eks.aws_iam_role.cluster: Destruction complete after 4s

Destroy complete! Resources: 28 destroyed.
PS C:\DDrive\MyData\Yogesh\git_repo\DevOps\kubernetes\aws-eks>